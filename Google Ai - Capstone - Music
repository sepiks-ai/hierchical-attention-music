{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/paulharrald/capstone-generative-hierachical-music?scriptVersionId=237914344\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"\"\"\"\nHierarchical Music Generation System\n===================================\n\nAuthor: Paul Harrald (paul@sepiks.ai)\n\nThis code implements a novel approach to music generation using a hierarchical token system \nthat addresses the long-term dependency problem in music generation. The key thesis is that\nby tokenizing music at multiple structural levels (structure → phrase → note), and building \nseparate models for each level, we can capture long-range dependencies that would be lost \nin flat, single-level approaches.\n\nThe hierarchical approach works as follows:\n1. A structure model generates high-level musical forms (intro, verse, chorus, etc.)\n2. For each structure token, a phrase model generates appropriate musical phrases\n3. For each phrase token, a note model generates the actual notes\n\nThis conditional hierarchy enforces musical coherence across longer time spans than\ntraditional note-by-note generation, leading to more structured compositions with \nrecognizable patterns.\n\nFuture Development:\n- The next step is to train on actual music datasets with hierarchical annotations\n- Several potential sources exist (SALAMI, Isophonics) that could be leveraged\n- Current GPU/execution time is too slow for large-scale training, but the proof\n  of concept works successfully!\n\nThe system currently can generate both rule-based compositions and neural model-based\nmusic (though training on larger *real* datasets would improve quality!).\n\nAh well. This is a good idea, and maybe novel. It's worth another look.\n\nBlog post: https://paulharrald.substack.com/p/towards-solving-the-long-range-dependency\n\n17th April 20025\n\n\"\"\"\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport IPython.display as ipd\nfrom scipy.io import wavfile\nimport random\nimport os\nfrom IPython.display import HTML, display, Audio\nimport json\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tqdm import tqdm\nimport pickle\nimport sys\nimport traceback\n\n# Try importing pretty_midi and install if needed\ntry:\n    import pretty_midi\n    PRETTY_MIDI_AVAILABLE = True\nexcept ImportError:\n    PRETTY_MIDI_AVAILABLE = False\n    print(\"pretty_midi is not available. Installing...\")\n    try:\n        import pip\n        pip.main(['install', 'pretty_midi'])\n        import pretty_midi\n        PRETTY_MIDI_AVAILABLE = True\n    except Exception as e:\n        print(f\"Could not install pretty_midi: {e}\")\n        print(\"MIDI functionality will be disabled.\")\n\n# Define token vocabularies for our generative models\nSTRUCTURE_TOKENS = [\"START\", \"intro\", \"verse\", \"chorus\", \"bridge\", \"outro\", \"EOM\"]\nPHRASE_TOKENS = [\"START\", \"ascending\", \"descending\", \"arpeggiated\", \"rhythmic\", \n                 \"sustained\", \"staccato\", \"call\", \"response\", \"EOM\"]\nNOTE_TOKENS = [\"START\"] + [str(i) for i in range(36, 85)] + [\"EOM\"]\n\n# Create token-to-id mappings\nstructure_to_id = {token: i for i, token in enumerate(STRUCTURE_TOKENS)}\nphrase_to_id = {token: i for i, token in enumerate(PHRASE_TOKENS)}\nnote_to_id = {token: i for i, token in enumerate(NOTE_TOKENS)}\n\n# Create id-to-token mappings\nid_to_structure = {i: token for token, i in structure_to_id.items()}\nid_to_phrase = {i: token for token, i in phrase_to_id.items()}\nid_to_note = {i: token for token, i in note_to_id.items()}\n\n# Define vocabulary sizes\nstructure_vocab_size = len(STRUCTURE_TOKENS)\nphrase_vocab_size = len(PHRASE_TOKENS)\nnote_vocab_size = len(NOTE_TOKENS)\n\n# Helper function for displaying chord names\ndef numeral_to_name(degree, scale_type='major'):\n    \"\"\"Convert scale degree to chord name.\"\"\"\n    major_names = {1: \"I\", 2: \"ii\", 3: \"iii\", 4: \"IV\", 5: \"V\", 6: \"vi\", 7: \"vii°\"}\n    minor_names = {1: \"i\", 2: \"ii°\", 3: \"III\", 4: \"iv\", 5: \"v\", 6: \"VI\", 7: \"VII\"}\n    \n    if scale_type == 'minor':\n        return minor_names.get(degree, str(degree))\n    else:\n        return major_names.get(degree, str(degree))\n\n\n#============================================================\n# PART 1: HIERARCHICAL MUSIC GENERATOR (RULE-BASED)\n#============================================================\n\nclass HierarchicalMusicGenerator:\n    def __init__(self):\n        # Musical parameters\n        self.sample_rate = 44100\n        self.bpm = 120\n        \n        # Define musical constants\n        self.STRUCTURE_TOKENS = [\"intro\", \"verse\", \"chorus\", \"bridge\", \"outro\", \"EOM\"]\n        self.PHRASE_TOKENS = [\n            \"ascending\", \"descending\", \"arpeggiated\", \"rhythmic\", \n            \"sustained\", \"staccato\", \"call\", \"response\", \"EOM\"\n        ]\n        \n        # Note tokens include MIDI note numbers (36-84) plus the EOM token\n        self.NOTE_TOKENS = list(range(36, 85)) + [\"EOM\"]\n        \n        # Define scales (semitone offsets from root)\n        self.scales = {\n            'major': [0, 2, 4, 5, 7, 9, 11],\n            'minor': [0, 2, 3, 5, 7, 8, 10],\n            'pentatonic': [0, 2, 4, 7, 9],\n            'blues': [0, 3, 5, 6, 7, 10]\n        }\n        \n        # Default parameters\n        self.root_note = 60  # C4 in MIDI\n        self.scale_type = 'major'\n        \n        # Structure model parameters\n        self.structure_temperature = 0.8\n        \n        # Phrase model parameters\n        self.phrase_temperature = 0.7\n        \n        # Note model parameters\n        self.note_temperature = 0.5\n        \n        # Internal state\n        self.current_structure = []\n        self.current_phrases = {}  # Map structure tokens to lists of phrases\n        self.current_notes = {}    # Map phrases to lists of notes\n        self.current_rhythm_patterns = {}  # Map phrases to rhythm patterns\n        self.current_chord_progressions = {}  # Map structure tokens to chord progressions\n        self.midi_file = None\n        self.audio_data = None\n        \n        # Initialize weights with default values (would be trained in a real model)\n        self._initialize_weights()\n    \n    def _initialize_weights(self):\n        \"\"\"Initialize probability weights for each level of the hierarchy.\n        In a real implementation, these would come from trained models.\"\"\"\n        \n        # 1. Structure level probabilities\n        # Define transition probabilities between structure tokens\n        self.structure_weights = {\n            \"START\": {\n                \"intro\": 0.7, \"verse\": 0.25, \"chorus\": 0.05, \"bridge\": 0.0, \"outro\": 0.0, \"EOM\": 0.0\n            },\n            \"intro\": {\n                \"intro\": 0.1, \"verse\": 0.7, \"chorus\": 0.15, \"bridge\": 0.0, \"outro\": 0.0, \"EOM\": 0.05\n            },\n            \"verse\": {\n                \"intro\": 0.0, \"verse\": 0.2, \"chorus\": 0.7, \"bridge\": 0.05, \"outro\": 0.0, \"EOM\": 0.05\n            },\n            \"chorus\": {\n                \"intro\": 0.0, \"verse\": 0.4, \"chorus\": 0.1, \"bridge\": 0.3, \"outro\": 0.15, \"EOM\": 0.05\n            },\n            \"bridge\": {\n                \"intro\": 0.0, \"verse\": 0.1, \"chorus\": 0.6, \"bridge\": 0.1, \"outro\": 0.15, \"EOM\": 0.05\n            },\n            \"outro\": {\n                \"intro\": 0.0, \"verse\": 0.0, \"chorus\": 0.0, \"bridge\": 0.0, \"outro\": 0.2, \"EOM\": 0.8\n            }\n        }\n        \n        # 2. Phrase level probabilities\n        # Define which phrases are more likely for each structure\n        self.phrase_weights = {\n            \"intro\": {\n                \"ascending\": 0.3, \"descending\": 0.1, \"arpeggiated\": 0.2, \n                \"rhythmic\": 0.1, \"sustained\": 0.2, \"staccato\": 0.05, \n                \"call\": 0.0, \"response\": 0.0, \"EOM\": 0.05\n            },\n            \"verse\": {\n                \"ascending\": 0.15, \"descending\": 0.15, \"arpeggiated\": 0.1, \n                \"rhythmic\": 0.25, \"sustained\": 0.05, \"staccato\": 0.1, \n                \"call\": 0.1, \"response\": 0.1, \"EOM\": 0.1\n            },\n            \"chorus\": {\n                \"ascending\": 0.1, \"descending\": 0.1, \"arpeggiated\": 0.15, \n                \"rhythmic\": 0.1, \"sustained\": 0.25, \"staccato\": 0.05, \n                \"call\": 0.1, \"response\": 0.1, \"EOM\": 0.05\n            },\n            \"bridge\": {\n                \"ascending\": 0.1, \"descending\": 0.1, \"arpeggiated\": 0.25, \n                \"rhythmic\": 0.15, \"sustained\": 0.1, \"staccato\": 0.1, \n                \"call\": 0.1, \"response\": 0.05, \"EOM\": 0.05\n            },\n            \"outro\": {\n                \"ascending\": 0.05, \"descending\": 0.3, \"arpeggiated\": 0.1, \n                \"rhythmic\": 0.1, \"sustained\": 0.3, \"staccato\": 0.0, \n                \"call\": 0.0, \"response\": 0.0, \"EOM\": 0.15\n            }\n        }\n        \n        # 3. Note level tendencies\n        # Define note patterns for each phrase type\n        # This is simplified - in a real model, this would be learned\n        self.note_patterns = {\n            \"ascending\": {\"direction\": 1, \"step_size\": 2, \"variability\": 1},\n            \"descending\": {\"direction\": -1, \"step_size\": 2, \"variability\": 1},\n            \"arpeggiated\": {\"pattern\": [0, 4, 7], \"octave_range\": 2},\n            \"rhythmic\": {\"note_pool\": [0, 2, 4, 7], \"repeat_prob\": 0.3},\n            \"sustained\": {\"note_pool\": [0, 4, 7], \"duration_factor\": 2.0},\n            \"staccato\": {\"note_pool\": [0, 2, 4, 5, 7, 9], \"duration_factor\": 0.5},\n            \"call\": {\"contour\": [0, 2, 4], \"end_on_dominant\": True},\n            \"response\": {\"contour\": [7, 5, 0], \"end_on_tonic\": True}\n        }\n    \n    # Convert MIDI note number to frequency\n    def midi_to_freq(self, midi_note):\n        if midi_note == \"EOM\":\n            return None\n        return 440 * (2 ** ((midi_note - 69) / 12))\n    \n    # Convert MIDI note to note name\n    def midi_to_note_name(self, midi_note):\n        if midi_note == \"EOM\":\n            return \"EOM\"\n        notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n        octave = (midi_note // 12) - 1\n        note = notes[midi_note % 12]\n        return f\"{note}{octave}\"\n    \n    def _sample_with_temperature(self, probabilities, temperature=1.0):\n        \"\"\"Sample from a probability distribution with temperature adjustment.\"\"\"\n        if temperature == 0:\n            # Just return the most likely token\n            return max(probabilities.items(), key=lambda x: x[1])[0]\n        \n        # Apply temperature\n        probs = np.array(list(probabilities.values()))\n        probs = np.power(probs, 1.0 / temperature)\n        probs = probs / np.sum(probs)\n        \n        # Sample\n        choice = np.random.choice(list(probabilities.keys()), p=probs)\n        return choice\n    \n    def generate_structure(self, prompt=None, max_length=10):\n        \"\"\"Generate the overall musical structure.\"\"\"\n        try:\n            if prompt is None:\n                current_token = \"START\"\n            else:\n                current_token = prompt\n            \n            structure = []\n            \n            for _ in range(max_length):\n                # Get probabilities for next token\n                probs = self.structure_weights.get(current_token, self.structure_weights[\"START\"])\n                \n                # Sample next token with temperature\n                next_token = self._sample_with_temperature(probs, self.structure_temperature)\n                \n                # If we hit EOM token, stop generation\n                if next_token == \"EOM\":\n                    break\n                \n                # Add to structure and update current token\n                structure.append(next_token)\n                current_token = next_token\n            \n            # Ensure we always have at least one structure element\n            if not structure:\n                structure = [\"verse\"]\n                print(\"Generated empty structure. Using default 'verse'.\")\n                \n            self.current_structure = structure\n            return structure\n        except Exception as e:\n            print(f\"Error generating structure: {e}\")\n            # Fallback to a simple structure\n            fallback = [\"intro\", \"verse\", \"chorus\", \"outro\"]\n            self.current_structure = fallback\n            return fallback\n    \n    def generate_phrases(self, structure_token, num_phrases=4):\n        \"\"\"Generate phrases for a specific structure token.\"\"\"\n        try:\n            phrases = []\n            \n            for _ in range(num_phrases):\n                # Get probabilities for phrases given the structure\n                probs = self.phrase_weights.get(structure_token, {})\n                if not probs:\n                    break\n                    \n                # Sample next phrase token with temperature\n                next_phrase = self._sample_with_temperature(probs, self.phrase_temperature)\n                \n                # If we hit EOM token, stop generation\n                if next_phrase == \"EOM\":\n                    break\n                    \n                # Add to phrases\n                phrases.append(next_phrase)\n            \n            # Ensure we have at least one phrase\n            if not phrases:\n                phrases = [\"rhythmic\"]\n                print(f\"Generated empty phrases for {structure_token}. Using default 'rhythmic'.\")\n            \n            # Store phrases for this structure token\n            if structure_token not in self.current_phrases:\n                self.current_phrases[structure_token] = []\n            \n            self.current_phrases[structure_token].extend(phrases)\n            return phrases\n        except Exception as e:\n            print(f\"Error generating phrases: {e}\")\n            # Fallback to a simple phrase\n            fallback = [\"rhythmic\"]\n            if structure_token not in self.current_phrases:\n                self.current_phrases[structure_token] = []\n            self.current_phrases[structure_token].extend(fallback)\n            return fallback\n    \n    def generate_notes(self, phrase_token, num_notes=8):\n        \"\"\"Generate notes for a specific phrase token.\"\"\"\n        try:\n            notes = []\n            pattern = self.note_patterns.get(phrase_token, {})\n            \n            if \"pattern\" in pattern:\n                # Use an arpeggio pattern\n                base_note = self.root_note\n                octave_range = pattern.get(\"octave_range\", 1)\n                \n                for _ in range(num_notes):\n                    # Choose a random note from the pattern\n                    pattern_index = random.randint(0, len(pattern[\"pattern\"]) - 1)\n                    octave_offset = random.randint(0, octave_range - 1) * 12\n                    \n                    # Calculate note\n                    note = base_note + pattern[\"pattern\"][pattern_index] + octave_offset\n                    \n                    # Ensure note is in a reasonable range\n                    if 36 <= note <= 84:\n                        notes.append(note)\n                    else:\n                        notes.append(self.root_note)\n                    \n                    # Occasional EOM check\n                    if random.random() < 0.05:\n                        break\n            \n            elif \"direction\" in pattern:\n                # Use a directional pattern (ascending/descending)\n                current_note = self.root_note\n                \n                for _ in range(num_notes):\n                    # Add the current note\n                    if 36 <= current_note <= 84:\n                        notes.append(current_note)\n                    else:\n                        notes.append(self.root_note)\n                    \n                    # Move in the pattern direction with some variability\n                    step = pattern[\"step_size\"] + random.randint(-pattern[\"variability\"], pattern[\"variability\"])\n                    current_note += pattern[\"direction\"] * step\n                    \n                    # Ensure we stay in scale\n                    current_note = self._adjust_to_scale(current_note)\n                    \n                    # Occasional EOM check\n                    if random.random() < 0.05:\n                        break\n            \n            elif \"note_pool\" in pattern:\n                # Use a pool of scale degrees\n                for _ in range(num_notes):\n                    # Choose a random note from the pool\n                    degree = random.choice(pattern[\"note_pool\"])\n                    octave_offset = random.randint(-1, 1) * 12\n                    \n                    # Calculate note\n                    note = self.root_note + degree + octave_offset\n                    \n                    # Ensure note is in a reasonable range\n                    if 36 <= note <= 84:\n                        notes.append(note)\n                    else:\n                        notes.append(self.root_note)\n                    \n                    # Occasional EOM or repetition\n                    if \"repeat_prob\" in pattern and random.random() < pattern[\"repeat_prob\"]:\n                        # Repeat the last note\n                        if notes:\n                            notes.append(notes[-1])\n                    \n                    if random.random() < 0.05:\n                        break\n            \n            elif \"contour\" in pattern:\n                # Use a melodic contour\n                base_note = self.root_note\n                \n                for i, interval in enumerate(pattern[\"contour\"]):\n                    note = base_note + interval\n                    \n                    # Ensure note is in a reasonable range\n                    if 36 <= note <= 84:\n                        notes.append(note)\n                    else:\n                        notes.append(self.root_note)\n                    \n                    if i == len(pattern[\"contour\"]) - 1:\n                        # Handle special ending conditions\n                        if pattern.get(\"end_on_tonic\", False):\n                            notes.append(self.root_note)\n                        elif pattern.get(\"end_on_dominant\", False):\n                            notes.append(self.root_note + 7)  # Dominant\n            \n            else:\n                # Default pattern: random notes from scale\n                for _ in range(num_notes):\n                    # Choose a random scale degree\n                    scale_degrees = self.scales[self.scale_type]\n                    degree = random.choice(scale_degrees)\n                    octave_offset = random.randint(-1, 1) * 12\n                    \n                    # Calculate note\n                    note = self.root_note + degree + octave_offset\n                    \n                    # Ensure note is in a reasonable range\n                    if 36 <= note <= 84:\n                        notes.append(note)\n                    else:\n                        notes.append(self.root_note)\n                    \n                    # Occasional EOM check\n                    if random.random() < 0.05:\n                        break\n            \n            # Ensure we have at least one note\n            if not notes:\n                notes = [self.root_note]\n                print(f\"Generated empty notes for {phrase_token}. Using root note.\")\n                \n            # Add EOM token at the end\n            notes.append(\"EOM\")\n            \n            # Store notes for this phrase\n            if phrase_token not in self.current_notes:\n                self.current_notes[phrase_token] = []\n            \n            self.current_notes[phrase_token].extend(notes[:-1])  # Exclude the EOM token for storage\n            \n            return notes\n        except Exception as e:\n            print(f\"Error generating notes: {e}\")\n            # Fallback to a simple note sequence\n            fallback = [self.root_note, self.root_note, \"EOM\"]\n            if phrase_token not in self.current_notes:\n                self.current_notes[phrase_token] = []\n            self.current_notes[phrase_token].extend(fallback[:-1])  # Exclude the EOM\n            return fallback\n    \n    def generate_rhythm_pattern(self, phrase_type, num_beats=8):\n        \"\"\"Generate a rhythm pattern appropriate for the given phrase type.\"\"\"\n        try:\n            # Basic patterns for different phrase types\n            pattern_options = {\n                \"rhythmic\": [\n                    [1, 0, 1, 0, 1, 0, 1, 0],  # Steady on-beat\n                    [0, 1, 0, 1, 0, 1, 0, 1],  # Steady off-beat\n                    [1, 0, 0, 1, 0, 0, 1, 0],  # Waltz-like\n                    [1, 0, 1, 1, 0, 1, 1, 0],  # Syncopated\n                ],\n                \"sustained\": [\n                    [1, 0, 0, 0, 1, 0, 0, 0],  # Long notes\n                    [1, 0, 0, 0, 0, 0, 0, 0],  # Very long notes\n                ],\n                \"staccato\": [\n                    [1, 1, 1, 1, 1, 1, 1, 1],  # Many short notes\n                    [1, 0, 1, 1, 0, 1, 1, 1],  # Varied short notes\n                ],\n                \"ascending\": [\n                    [1, 0, 1, 0, 1, 0, 1, 0],  # Even rhythm for scale\n                ],\n                \"descending\": [\n                    [1, 0, 1, 0, 1, 0, 1, 0],  # Even rhythm for scale\n                ],\n                \"arpeggiated\": [\n                    [1, 1, 1, 1, 0, 0, 0, 0],  # Group of notes then rest\n                    [1, 0, 1, 0, 1, 0, 1, 0],  # Regular arpeggio\n                ],\n                \"call\": [\n                    [1, 0, 1, 0, 0, 0, 0, 0],  # Short call\n                ],\n                \"response\": [\n                    [0, 0, 0, 0, 1, 0, 1, 0],  # Delayed response\n                ]\n            }\n            \n            # Default pattern if phrase type not found\n            default_patterns = [[1, 0, 1, 0, 1, 0, 1, 0], [1, 1, 0, 1, 0, 1, 0, 0]]\n            \n            # Get patterns for this phrase type or use default\n            available_patterns = pattern_options.get(phrase_type, default_patterns)\n            \n            # Choose a pattern based on temperature\n            pattern_index = random.randint(0, len(available_patterns) - 1)\n            base_pattern = available_patterns[pattern_index]\n            \n            # Adjust the pattern length if needed\n            if len(base_pattern) < num_beats:\n                # Repeat the pattern\n                full_pattern = (base_pattern * (num_beats // len(base_pattern) + 1))[:num_beats]\n            elif len(base_pattern) > num_beats:\n                # Truncate the pattern\n                full_pattern = base_pattern[:num_beats]\n            else:\n                full_pattern = base_pattern\n            \n            # Store the pattern\n            if phrase_type not in self.current_rhythm_patterns:\n                self.current_rhythm_patterns[phrase_type] = []\n            self.current_rhythm_patterns[phrase_type].append(full_pattern)\n            \n            return full_pattern\n        except Exception as e:\n            print(f\"Error generating rhythm pattern: {e}\")\n            # Fallback to a simple pattern\n            fallback = [1, 0, 1, 0, 1, 0, 1, 0][:num_beats]\n            if phrase_type not in self.current_rhythm_patterns:\n                self.current_rhythm_patterns[phrase_type] = []\n            self.current_rhythm_patterns[phrase_type].append(fallback)\n            return fallback\n    \n    def apply_rhythm_to_notes(self, notes, rhythm_pattern, base_duration=0.25):\n        \"\"\"Apply a rhythm pattern to a sequence of notes.\"\"\"\n        try:\n            # Initialize the result list with notes and durations\n            noted_with_duration = []\n            \n            # Count how many actual notes we need based on the rhythm pattern\n            notes_needed = sum(rhythm_pattern)\n            \n            # Ensure we have enough notes\n            effective_notes = []\n            for n in notes:\n                if n != \"EOM\" and n is not None:\n                    effective_notes.append(n)\n            \n            if len(effective_notes) < notes_needed:\n                # Pad with repeats of the last note\n                last_note = effective_notes[-1] if effective_notes else self.root_note\n                effective_notes = effective_notes + [last_note] * (notes_needed - len(effective_notes))\n            \n            # Apply the rhythm pattern\n            note_index = 0\n            for beat in rhythm_pattern:\n                if beat == 1:  # Play a note\n                    if note_index < len(effective_notes):\n                        note = effective_notes[note_index]\n                        # Duration can be base_duration or longer for certain phrases\n                        noted_with_duration.append((note, base_duration))\n                        note_index += 1\n                else:  # Rest or extend previous note\n                    # We could extend the previous note instead of having a rest\n                    if random.random() < 0.3 and noted_with_duration:  # 30% chance to extend\n                        prev_note, prev_duration = noted_with_duration[-1]\n                        noted_with_duration[-1] = (prev_note, prev_duration + base_duration)\n                    else:\n                        # Add a rest (None)\n                        noted_with_duration.append((None, base_duration))\n            \n            return noted_with_duration\n        except Exception as e:\n            print(f\"Error applying rhythm to notes: {e}\")\n            # Fallback to simple notes with duration\n            fallback = [(note, base_duration) for note in notes if note != \"EOM\" and note is not None]\n            if not fallback:\n                fallback = [(self.root_note, base_duration)]\n            return fallback\n    \n    def generate_chord_progression(self, structure_token):\n        \"\"\"Generate a chord progression suitable for the given structure token.\"\"\"\n        try:\n            # Define common chord progressions by root scale degree\n            # Using Roman numeral notation: I = 1st degree, IV = 4th degree, etc.\n            progressions = {\n                \"intro\": [\n                    [1, 4, 5, 1],  # I-IV-V-I\n                    [1, 6, 4, 5],  # I-vi-IV-V\n                ],\n                \"verse\": [\n                    [1, 6, 4, 5],  # I-vi-IV-V\n                    [1, 5, 6, 4],  # I-V-vi-IV\n                    [1, 4, 1, 5],  # I-IV-I-V\n                ],\n                \"chorus\": [\n                    [1, 5, 6, 4],  # I-V-vi-IV\n                    [1, 4, 5, 5],  # I-IV-V-V\n                    [4, 5, 1, 6],  # IV-V-I-vi\n                ],\n                \"bridge\": [\n                    [6, 4, 1, 5],  # vi-IV-I-V\n                    [4, 5, 3, 6],  # IV-V-iii-vi\n                    [2, 5, 1, 6],  # ii-V-I-vi\n                ],\n                \"outro\": [\n                    [1, 5, 1, 1],  # I-V-I-I\n                    [1, 4, 1, 5],  # I-IV-I-V\n                    [4, 5, 1, 1],  # IV-V-I-I\n                ]\n            }\n            \n            # Default progression if structure not found\n            default_progression = [1, 4, 5, 1]  # I-IV-V-I\n            \n            # Get progressions for this structure or use default\n            available_progressions = progressions.get(structure_token, [default_progression])\n            \n            # Choose a progression based on temperature\n            progression_index = random.randint(0, len(available_progressions) - 1)\n            chosen_progression = available_progressions[progression_index]\n            \n            # Store the chord progression\n            if structure_token not in self.current_chord_progressions:\n                self.current_chord_progressions[structure_token] = []\n            self.current_chord_progressions[structure_token].append(chosen_progression)\n            \n            return chosen_progression\n        except Exception as e:\n            print(f\"Error generating chord progression: {e}\")\n            # Fallback to a simple progression\n            fallback = [1, 4, 5, 1]\n            if structure_token not in self.current_chord_progressions:\n                self.current_chord_progressions[structure_token] = []\n            self.current_chord_progressions[structure_token].append(fallback)\n            return fallback\n    \n    def create_chord(self, degree, voicing=\"triad\"):\n        \"\"\"Create a chord based on a scale degree.\"\"\"\n        try:\n            # Get the current scale\n            scale_degrees = self.scales[self.scale_type]\n            \n            # Adjust the degree to 0-based index\n            degree_index = degree - 1\n            \n            # Find the root note for this degree\n            if 0 <= degree_index < len(scale_degrees):\n                root_offset = scale_degrees[degree_index]\n            else:\n                # Default to tonic if degree is out of range\n                root_offset = scale_degrees[0]\n                \n            root_note = self.root_note + root_offset\n            \n            # Create different chord voicings\n            if voicing == \"triad\":\n                # Basic triad: root, third, fifth\n                third_index = (degree_index + 2) % len(scale_degrees)\n                fifth_index = (degree_index + 4) % len(scale_degrees)\n                \n                third_offset = scale_degrees[third_index]\n                fifth_offset = scale_degrees[fifth_index]\n                \n                # Adjust for proper octave\n                while third_offset < root_offset:\n                    third_offset += 12\n                while fifth_offset < third_offset:\n                    fifth_offset += 12\n                \n                third_note = self.root_note + third_offset\n                fifth_note = self.root_note + fifth_offset\n                \n                return [root_note, third_note, fifth_note]\n            \n            elif voicing == \"seventh\":\n                # Seventh chord: root, third, fifth, seventh\n                third_index = (degree_index + 2) % len(scale_degrees)\n                fifth_index = (degree_index + 4) % len(scale_degrees)\n                seventh_index = (degree_index + 6) % len(scale_degrees)\n                \n                third_offset = scale_degrees[third_index]\n                fifth_offset = scale_degrees[fifth_index]\n                seventh_offset = scale_degrees[seventh_index]\n                \n                # Adjust for proper octave\n                while third_offset < root_offset:\n                    third_offset += 12\n                while fifth_offset < third_offset:\n                    fifth_offset += 12\n                while seventh_offset < fifth_offset:\n                    seventh_offset += 12\n                \n                third_note = self.root_note + third_offset\n                fifth_note = self.root_note + fifth_offset\n                seventh_note = self.root_note + seventh_offset\n                \n                return [root_note, third_note, fifth_note, seventh_note]\n            \n            else:  # Just the root\n                return [root_note]\n        except Exception as e:\n            print(f\"Error creating chord: {e}\")\n            # Fallback to root note only\n            return [self.root_note]\n    \n    def _adjust_to_scale(self, note):\n        \"\"\"Adjust a note to fit the current scale.\"\"\"\n        try:\n            scale_degrees = self.scales[self.scale_type]\n            note_in_scale = False\n            \n            # Check if the note is already in scale\n            note_degree = (note - self.root_note) % 12\n            if note_degree in scale_degrees:\n                note_in_scale = True\n            \n            if not note_in_scale:\n                # Find the closest scale degree\n                closest_degree = min(scale_degrees, key=lambda x: abs(x - note_degree))\n                note = note - note_degree + closest_degree\n            \n            return note\n        except Exception as e:\n            print(f\"Error adjusting note to scale: {e}\")\n            # Fallback to root note\n            return self.root_note\n    \n    def generate_full_composition(self, structure_prompt=None):\n        \"\"\"Generate a full piece from structure to notes with rhythm and chords.\"\"\"\n        try:\n            # 1. Generate the overall structure\n            structure = self.generate_structure(prompt=structure_prompt)\n            print(f\"Generated structure: {structure}\")\n            \n            # 2. For each structure token, generate chord progression and phrases\n            for struct in structure:\n                # Generate chord progression for this structure\n                chord_progression = self.generate_chord_progression(struct)\n                chord_names = [f\"{numeral_to_name(degree, self.scale_type)}\" for degree in chord_progression]\n                print(f\"  {struct} chord progression: {chord_names}\")\n                \n                # Generate phrases\n                phrases = self.generate_phrases(struct)\n                print(f\"  {struct} phrases: {phrases}\")\n                \n                # 3. For each phrase, generate rhythm pattern and notes\n                for phrase in phrases:\n                    # Generate rhythm pattern\n                    rhythm = self.generate_rhythm_pattern(phrase)\n                    \n                    # Generate notes\n                    notes = self.generate_notes(phrase)\n                    \n                    # Display notes (excluding EOM)\n                    note_names = []\n                    for n in notes:\n                        if n != \"EOM\":\n                            try:\n                                note_names.append(self.midi_to_note_name(n))\n                            except:\n                                note_names.append(str(n))\n                    print(f\"    {phrase} notes: {note_names}\")\n            \n            return {\n                \"structure\": structure,\n                \"chord_progressions\": self.current_chord_progressions,\n                \"phrases\": self.current_phrases,\n                \"rhythm_patterns\": self.current_rhythm_patterns,\n                \"notes\": self.current_notes\n            }\n        except Exception as e:\n            print(f\"Error generating composition: {e}\")\n            traceback.print_exc()\n            # Return whatever we have so far\n            return {\n                \"structure\": self.current_structure,\n                \"chord_progressions\": self.current_chord_progressions,\n                \"phrases\": self.current_phrases,\n                \"rhythm_patterns\": self.current_rhythm_patterns,\n                \"notes\": self.current_notes\n            }\n    \n    # Generate a simple sine wave for a given note\n    def generate_sine_wave(self, freq, duration, amplitude=0.5):\n        \"\"\"Generate a sine wave for a given frequency.\"\"\"\n        try:\n            if freq is None:\n                return np.zeros(int(self.sample_rate * duration))\n                \n            t = np.linspace(0, duration, int(self.sample_rate * duration), endpoint=False)\n            \n            # Apply an amplitude envelope\n            envelope = np.ones_like(t)\n            attack = int(0.1 * len(t))\n            release = int(0.3 * len(t))\n            envelope[:attack] = np.linspace(0, 1, attack)\n            envelope[-release:] = np.linspace(1, 0, release)\n            \n            return amplitude * envelope * np.sin(2 * np.pi * freq * t)\n        except Exception as e:\n            print(f\"Error generating sine wave: {e}\")\n            # Return silence\n            return np.zeros(int(self.sample_rate * duration))\n    \n    def enhance_sine_wave(self):\n        \"\"\"Replace the simple sine wave generator with a more complex one that produces richer sound.\"\"\"\n        try:\n            # Store the original method as a backup\n            self._original_sine_wave = self.generate_sine_wave\n            \n            # Define an enhanced version with harmonics\n            def enhanced_sine_wave(freq, duration, amplitude=0.7):  # Higher default amplitude\n                if freq is None:\n                    return np.zeros(int(self.sample_rate * duration))\n                    \n                t = np.linspace(0, duration, int(self.sample_rate * duration), endpoint=False)\n                \n                # Create a more complex waveform with harmonics (sounds more like a piano)\n                # Fundamental frequency\n                wave = amplitude * np.sin(2 * np.pi * freq * t)\n                \n                # Add harmonics\n                wave += 0.3 * amplitude * np.sin(2 * np.pi * (freq * 2) * t)  # 2nd harmonic (octave)\n                wave += 0.15 * amplitude * np.sin(2 * np.pi * (freq * 3) * t)  # 3rd harmonic\n                wave += 0.075 * amplitude * np.sin(2 * np.pi * (freq * 4) * t)  # 4th harmonic\n                \n                # Apply a more sophisticated envelope\n                attack = int(0.05 * len(t))\n                decay = int(0.1 * len(t))\n                release = int(0.3 * len(t))\n                sustain_level = 0.8\n                \n                envelope = np.ones_like(t) * sustain_level\n                envelope[:attack] = np.linspace(0, 1, attack)\n                envelope[attack:attack+decay] = np.linspace(1, sustain_level, decay)\n                envelope[-release:] = np.linspace(sustain_level, 0, release)\n                \n                return envelope * wave\n            \n            # Replace the method\n            self.generate_sine_wave = enhanced_sine_wave\n            \n            # Return self for method chaining\n            return self\n        except Exception as e:\n            print(f\"Error enhancing sine wave: {e}\")\n            # Keep the original method\n            return self\n    \n    def render_with_chords_and_rhythm(self):\n        \"\"\"Render the composition with chords and rhythmic patterns.\"\"\"\n        try:\n            if not self.current_structure:\n                print(\"No composition generated yet.\")\n                return None\n            \n            # Test tone - add a simple sine wave to confirm audio generation works\n            test_duration = 1.0  # seconds\n            test_tone = self.generate_sine_wave(440, test_duration, amplitude=0.5) \n            \n            # Calculate the total duration (estimate)\n            seconds_per_beat = 60.0 / self.bpm\n            base_duration = seconds_per_beat  # Quarter note duration\n            \n            # Create empty audio array (estimate size first)\n            # More reasonable initial size estimate based on structure\n            estimated_duration = min(120, max(30, len(self.current_structure) * 15))\n            audio_data = np.zeros(int(self.sample_rate * estimated_duration))\n            \n            # Current position in seconds\n            current_position = 0.0\n            \n            # Generate audio for each structure element\n            for struct_index, struct in enumerate(self.current_structure):\n                # Get chord progression for this structure\n                if struct in self.current_chord_progressions and self.current_chord_progressions[struct]:\n                    chord_progression = self.current_chord_progressions[struct][0]  # Use the first progression\n                else:\n                    # Generate a new one if missing\n                    chord_progression = self.generate_chord_progression(struct)\n                \n                print(f\"Rendering {struct} with chord progression: {[numeral_to_name(d, self.scale_type) for d in chord_progression]}\")\n                \n                # Get phrases for this structure\n                struct_phrases = self.current_phrases.get(struct, [])\n                \n                for phrase_index, phrase in enumerate(struct_phrases):\n                    # Get rhythm pattern for this phrase\n                    if phrase in self.current_rhythm_patterns and self.current_rhythm_patterns[phrase]:\n                        rhythm_pattern = self.current_rhythm_patterns[phrase][0]  # Use the first pattern\n                    else:\n                        # Generate a new one if missing\n                        rhythm_pattern = self.generate_rhythm_pattern(phrase)\n                    \n                    # Get notes for this phrase\n                    phrase_notes = self.current_notes.get(phrase, [])\n                    \n                    # Apply rhythm to the notes\n                    notes_with_duration = self.apply_rhythm_to_notes(\n                        phrase_notes, \n                        rhythm_pattern,\n                        base_duration=base_duration\n                    )\n                    \n                    # Determine which chord to use (cycle through progression)\n                    chord_index = (phrase_index % len(chord_progression))\n                    current_chord_degree = chord_progression[chord_index]\n                    \n                    # Create the chord\n                    chord_voicing = \"triad\" if random.random() < 0.7 else \"seventh\"  # 70% triads, 30% sevenths\n                    chord_notes = self.create_chord(current_chord_degree, voicing=chord_voicing)\n                    \n                    # Calculate total duration of this phrase\n                    phrase_duration = sum(duration for _, duration in notes_with_duration)\n                    \n                    # Generate chord audio (sustained through the phrase)\n                    chord_audio = np.zeros(int(self.sample_rate * phrase_duration))\n                    \n                    # Break chord into arpeggiated or block based on phrase type\n                    # Fix for the chord audio addition in render_with_chords_and_rhythm\n                    if phrase == \"arpeggiated\":\n                        # Arpeggiate the chord\n                        for i, chord_note in enumerate(chord_notes):\n                            chord_freq = self.midi_to_freq(chord_note)\n                            # Stagger the chord notes\n                            note_duration = phrase_duration / len(chord_notes)\n                            start_sample = int(i * note_duration * self.sample_rate)\n                            end_sample = min(int((i + 1) * note_duration * self.sample_rate), len(chord_audio))\n                            \n                            if start_sample < len(chord_audio) and end_sample <= len(chord_audio):\n                                note_audio = self.generate_sine_wave(chord_freq, note_duration, amplitude=0.3)\n                                # Make sure we're not going beyond bounds\n                                actual_len = min(len(note_audio), end_sample - start_sample)\n                                chord_audio[start_sample:start_sample + actual_len] += note_audio[:actual_len]\n                    else:\n                        # Block chord (all notes together)\n                        for chord_note in chord_notes:\n                            chord_freq = self.midi_to_freq(chord_note)\n                            note_audio = self.generate_sine_wave(chord_freq, phrase_duration, amplitude=0.2)\n                            chord_audio += note_audio\n                    \n                    # Generate audio for each note with its rhythm\n                    note_start = 0\n                    for note_info in notes_with_duration:\n                        note, duration = note_info\n                        \n                        if note is not None and note != \"EOM\":\n                            # Get note frequency\n                            freq = self.midi_to_freq(note)\n                            \n                            # Generate note audio\n                            note_audio = self.generate_sine_wave(freq, duration, amplitude=0.5)\n                            \n                            # Add to the audio data\n                            start_sample = int((current_position + note_start) * self.sample_rate)\n                            end_sample = start_sample + len(note_audio)\n                            \n                            # Ensure we don't exceed array bounds\n                            if end_sample > len(audio_data):\n                                # Extend audio data\n                                padding = np.zeros(end_sample - len(audio_data) + self.sample_rate)\n                                audio_data = np.concatenate((audio_data, padding))\n                            \n                            # Add melody note\n                            audio_data[start_sample:end_sample] += note_audio\n                        \n                        # Move forward in time for the next note\n                        note_start += duration\n                    \n                    # Add the chord audio for this phrase\n                    start_sample = int(current_position * self.sample_rate)\n                    end_sample = start_sample + len(chord_audio)\n                    \n                    # Ensure we don't exceed array bounds\n                    if end_sample > len(audio_data):\n                        # Extend audio data\n                        padding = np.zeros(end_sample - len(audio_data) + self.sample_rate)\n                        audio_data = np.concatenate((audio_data, padding))\n                    \n                    # Add chord audio\n                    audio_data[start_sample:end_sample] += chord_audio\n                    \n                    # Update position for next phrase\n                    current_position += phrase_duration\n                    \n                    # Add a small pause between phrases\n                    current_position += base_duration * 0.5\n                \n                # Add a larger pause between structure elements\n                current_position += base_duration * 2\n            \n            # Trim any unused audio buffer\n            actual_samples = int(current_position * self.sample_rate) + self.sample_rate  # Add a bit of tail\n            if actual_samples < len(audio_data):\n                audio_data = audio_data[:actual_samples]\n            \n            # Normalize audio to prevent clipping\n            max_amplitude = np.max(np.abs(audio_data))\n            if max_amplitude > 0:\n                audio_data = audio_data / max_amplitude * 0.9\n            \n            self.audio_data = audio_data\n            return audio_data\n        except Exception as e:\n            print(f\"Error rendering audio: {e}\")\n            traceback.print_exc()\n            # Return a short silent buffer as fallback\n            print(\"Creating silent audio as fallback.\")\n            self.audio_data = np.zeros(int(self.sample_rate * 3))\n            return self.audio_data\n    \n    def render_audio(self):\n        \"\"\"Render the composition as audio with enhanced volume and clarity.\"\"\"\n        return self.render_with_chords_and_rhythm()\n    \n    def play_audio(self):\n        \"\"\"Basic audio playback function at double speed.\"\"\"\n        try:\n            if self.audio_data is None:\n                self.render_audio()\n                    \n            if self.audio_data is None:\n                print(\"No audio data available.\")\n                return None\n            \n            # Use double speed by doubling the sample rate\n            return ipd.Audio(self.audio_data, rate=self.sample_rate * 2)\n        except Exception as e:\n            print(f\"Error playing audio: {e}\")\n            return ipd.Audio(np.zeros(self.sample_rate), rate=self.sample_rate * 2)\n\n    def play_audio_fixed(self):\n        \"\"\"Enhanced audio playback with debugging and visualization, at double speed.\"\"\"\n        try:\n            if self.audio_data is None:\n                print(\"Rendering audio...\")\n                self.render_audio()\n                    \n            if self.audio_data is None:\n                print(\"ERROR: No audio data was generated.\")\n                return None\n            \n            # Check if audio data contains actual sound\n            max_amp = np.max(np.abs(self.audio_data))\n            if max_amp < 0.01:\n                print(f\"WARNING: Audio amplitude is very low ({max_amp}). This might be inaudible.\")\n            \n            # Print audio statistics for debugging\n            print(f\"Audio data shape: {self.audio_data.shape}\")\n            # Display duration at double speed\n            print(f\"Audio duration (2x speed): {len(self.audio_data)/(self.sample_rate * 2):.2f} seconds\")\n            print(f\"Sample rate (playback): {self.sample_rate * 2} Hz\")\n            print(f\"Max amplitude: {max_amp:.4f}\")\n            \n            # Create an audio player at double speed\n            audio_player = ipd.Audio(self.audio_data, rate=self.sample_rate * 2, autoplay=True)\n            \n            # Visualize the audio waveform\n            plt.figure(figsize=(12, 3))\n            plt.plot(self.audio_data[:min(len(self.audio_data), 100000)])\n            plt.title(\"Audio Waveform (first 100,000 samples)\")\n            plt.xlabel(\"Sample\")\n            plt.ylabel(\"Amplitude\")\n            plt.grid(True, alpha=0.3)\n            plt.show()\n            \n            print(\"2x Speed Playback:\")\n            display(audio_player)\n            \n            return audio_player\n        except Exception as e:\n            print(f\"Error in audio playback: {e}\")\n            # Return a silent audio as fallback\n            fallback_audio = np.zeros(self.sample_rate)  # 1 second of silence\n            print(\"Falling back to silent audio due to error.\")\n            return ipd.Audio(fallback_audio, rate=self.sample_rate * 2)\n    \n    def save_audio(self, filename=\"generated_music.wav\"):\n        \"\"\"Save audio to a file.\"\"\"\n        try:\n            if self.audio_data is None:\n                self.render_audio()\n                \n            if self.audio_data is None:\n                print(\"No audio data to save.\")\n                return None\n            \n            # Make sure the directory exists\n            dirname = os.path.dirname(filename)\n            if dirname:\n                os.makedirs(dirname, exist_ok=True)\n            \n            wavfile.write(filename, self.sample_rate, self.audio_data.astype(np.float32))\n            print(f\"Audio saved to {filename}\")\n            return filename\n        except Exception as e:\n            print(f\"Error saving audio: {e}\")\n            return None\n    \n    def create_midi(self, filename=\"hierarchical_composition.mid\"):\n        \"\"\"Create a MIDI file with melody and chord tracks.\"\"\"\n        if not PRETTY_MIDI_AVAILABLE:\n            print(\"pretty_midi is not available. Cannot generate MIDI.\")\n            return None\n        \n        try:\n            # Create a PrettyMIDI object\n            midi = pretty_midi.PrettyMIDI(initial_tempo=self.bpm)\n            \n            # Create melody instrument (piano)\n            melody_instrument = pretty_midi.Instrument(program=0)  # Piano\n            \n            # Create chord instrument (string ensemble)\n            chord_instrument = pretty_midi.Instrument(program=48)  # String Ensemble\n            \n            # Track timing\n            current_time = 0\n            \n            # For each structure element\n            for struct_index, struct in enumerate(self.current_structure):\n                # Get chord progression for this structure\n                if struct in self.current_chord_progressions and self.current_chord_progressions[struct]:\n                    chord_progression = self.current_chord_progressions[struct][0]  # Use the first progression\n                else:\n                    # Generate a new one if missing\n                    chord_progression = self.generate_chord_progression(struct)\n                \n                # Get phrases for this structure\n                struct_phrases = self.current_phrases.get(struct, [])\n                \n                for phrase_index, phrase in enumerate(struct_phrases):\n                    # Get rhythm pattern for this phrase\n                    if phrase in self.current_rhythm_patterns and self.current_rhythm_patterns[phrase]:\n                        rhythm_pattern = self.current_rhythm_patterns[phrase][0]  # Use the first pattern\n                    else:\n                        # Generate a new one if missing\n                        rhythm_pattern = self.generate_rhythm_pattern(phrase)\n                    \n                    # Get notes for this phrase\n                    phrase_notes = self.current_notes.get(phrase, [])\n                    \n                    # Apply rhythm to the notes\n                    notes_with_duration = self.apply_rhythm_to_notes(\n                        phrase_notes, \n                        rhythm_pattern,\n                        base_duration=0.25  # Quarter note\n                    )\n                    \n                    # Calculate total phrase duration\n                    phrase_duration = sum(duration for _, duration in notes_with_duration)\n                    \n                    # Determine which chord to use\n                    chord_index = (phrase_index % len(chord_progression))\n                    current_chord_degree = chord_progression[chord_index]\n                    \n                    # Create the chord\n                    chord_voicing = \"triad\" if random.random() < 0.7 else \"seventh\"  # 70% triads, 30% sevenths\n                    chord_notes = self.create_chord(current_chord_degree, voicing=chord_voicing)\n                    \n                    # Add chord to chord track\n                    for chord_note in chord_notes:\n                        if chord_note is not None and chord_note != \"EOM\":\n                            chord_midi_note = pretty_midi.Note(\n                                velocity=80,  # Softer than melody\n                                pitch=chord_note,\n                                start=current_time,\n                                end=current_time + phrase_duration\n                            )\n                            chord_instrument.notes.append(chord_midi_note)\n                    \n                    # Add melody notes with rhythm\n                    note_start_time = current_time\n                    for note_info in notes_with_duration:\n                        note, duration = note_info\n                        \n                        if note is not None and note != \"EOM\":\n                            melody_midi_note = pretty_midi.Note(\n                                velocity=100,\n                                pitch=note,\n                                start=note_start_time,\n                                end=note_start_time + duration\n                            )\n                            melody_instrument.notes.append(melody_midi_note)\n                        \n                        # Move forward in time\n                        note_start_time += duration\n                    \n                    # Update the current time\n                    current_time += phrase_duration\n                    \n                    # Add a small pause between phrases\n                    current_time += 0.5\n                \n                # Add a larger pause between structure elements\n                current_time += 1.0\n            \n            # Add instruments to the MIDI file\n            midi.instruments.append(melody_instrument)\n            midi.instruments.append(chord_instrument)\n            \n            # Make sure the directory exists\n            dirname = os.path.dirname(filename)\n            if dirname:\n                os.makedirs(dirname, exist_ok=True)\n            \n            # Save to file\n            midi.write(filename)\n            self.midi_file = filename\n            print(f\"MIDI file created: {filename}\")\n            \n            return filename\n        except Exception as e:\n            print(f\"Error creating MIDI file: {e}\")\n            traceback.print_exc()\n            return None\n    \n    def visualize_composition(self):\n        \"\"\"Visualize the hierarchical structure of the composition.\"\"\"\n        try:\n            if not self.current_structure:\n                print(\"No composition generated yet.\")\n                return\n            \n            # Create a figure with multiple subplots\n            fig = plt.figure(figsize=(15, 10))\n            \n            # 1. Structure level visualization\n            plt.subplot(4, 1, 1)\n            for i, struct in enumerate(self.current_structure):\n                plt.text(i, 0.5, struct, fontsize=12, ha='center')\n                \n                # Add chord progression if available\n                if struct in self.current_chord_progressions and self.current_chord_progressions[struct]:\n                    chord_prog = self.current_chord_progressions[struct][0]\n                    chord_names = [numeral_to_name(degree, self.scale_type) for degree in chord_prog]\n                    plt.text(i, 0.2, \" → \".join(chord_names), fontsize=8, ha='center')\n                    \n            plt.xlim(-0.5, len(self.current_structure) - 0.5)\n            plt.ylim(0, 1)\n            plt.title(\"Musical Structure with Chord Progressions\")\n            plt.axis(\"off\")\n            \n            # 2. Phrase level visualization\n            plt.subplot(4, 1, 2)\n            phrase_count = 0\n            structure_boundaries = [0]\n            structure_labels = []\n            \n            for struct in self.current_structure:\n                struct_phrases = self.current_phrases.get(struct, [])\n                for j, phrase in enumerate(struct_phrases):\n                    plt.text(phrase_count + j, 0.5, phrase, fontsize=10, ha='center')\n                \n                phrase_count += len(struct_phrases)\n                structure_boundaries.append(phrase_count)\n                structure_labels.append(struct)\n            \n            # Add vertical lines for structure boundaries\n            for boundary in structure_boundaries[:-1]:\n                plt.axvline(x=boundary - 0.5, color='gray', linestyle='--', alpha=0.5)\n            \n            plt.xlim(-0.5, phrase_count - 0.5)\n            plt.ylim(0, 1)\n            plt.title(\"Phrases\")\n            plt.axis(\"off\")\n            \n            # 3. Rhythm visualization\n            plt.subplot(4, 1, 3)\n            rhythm_position = 0\n            \n            for struct in self.current_structure:\n                struct_phrases = self.current_phrases.get(struct, [])\n                \n                for phrase in struct_phrases:\n                    # Get rhythm pattern if available\n                    if phrase in self.current_rhythm_patterns and self.current_rhythm_patterns[phrase]:\n                        rhythm = self.current_rhythm_patterns[phrase][0]\n                        \n                        # Plot rhythm pattern\n                        for i, beat in enumerate(rhythm):\n                            if beat == 1:\n                                plt.plot(rhythm_position + i, 0.5, 'o', markersize=8, color='blue')\n                            else:\n                                plt.plot(rhythm_position + i, 0.5, 'x', markersize=6, color='lightgray', alpha=0.5)\n                        \n                        rhythm_position += len(rhythm)\n                    else:\n                        # No rhythm pattern available\n                        rhythm_position += 8  # Default length\n            \n            plt.title(\"Rhythm Patterns (o = note, x = rest)\")\n            plt.xlim(-0.5, rhythm_position - 0.5)\n            plt.ylim(0, 1)\n            plt.axis(\"off\")\n            \n            # 4. Note level visualization (piano roll style)\n            ax = plt.subplot(4, 1, 4)\n            note_position = 0\n            phrase_boundaries = [0]\n            phrase_labels = []\n            \n            for struct in self.current_structure:\n                struct_phrases = self.current_phrases.get(struct, [])\n                \n                for phrase in struct_phrases:\n                    phrase_notes = self.current_notes.get(phrase, [])\n                    \n                    for note in phrase_notes:\n                        if note != \"EOM\" and isinstance(note, int):\n                            plt.plot(note_position, note, 'o', markersize=8)\n                        note_position += 1\n                    \n                    phrase_boundaries.append(note_position)\n                    phrase_labels.append(phrase)\n            \n            # Add vertical lines for phrase boundaries\n            for boundary in phrase_boundaries[:-1]:\n                plt.axvline(x=boundary - 0.5, color='green', linestyle='--', alpha=0.3)\n            \n            plt.ylim(36, 84)\n            plt.title(\"Notes (MIDI pitch)\")\n            plt.xlabel(\"Time step\")\n            plt.ylabel(\"MIDI Note Number\")\n            plt.grid(True, alpha=0.3)\n            \n            plt.tight_layout()\n            return fig\n        except Exception as e:\n            print(f\"Error visualizing composition: {e}\")\n            return None\n    \n    def save_composition(self, filename=\"composition.json\"):\n        \"\"\"Save the generated composition to a JSON file.\"\"\"\n        try:\n            # Convert the composition to a serializable format\n            composition = {\n                \"structure\": self.current_structure,\n                \"phrases\": {k: v for k, v in self.current_phrases.items()},\n                \"notes\": {k: [n if isinstance(n, int) else \"EOM\" for n in v] \n                         for k, v in self.current_notes.items()},\n                \"rhythm_patterns\": {k: v for k, v in self.current_rhythm_patterns.items()},\n                \"chord_progressions\": {k: v for k, v in self.current_chord_progressions.items()},\n                \"parameters\": {\n                    \"root_note\": self.root_note,\n                    \"scale_type\": self.scale_type,\n                    \"bpm\": self.bpm\n                }\n            }\n            \n            # Make sure the directory exists\n            dirname = os.path.dirname(filename)\n            if dirname:\n                os.makedirs(dirname, exist_ok=True)\n            \n            # Save to file\n            with open(filename, 'w') as f:\n                json.dump(composition, f, indent=2)\n            \n            print(f\"Composition saved to {filename}\")\n            return filename\n        except Exception as e:\n            print(f\"Error saving composition: {e}\")\n            return None\n    \n    def load_composition(self, filename):\n        \"\"\"Load a composition from a JSON file.\"\"\"\n        try:\n            with open(filename, 'r') as f:\n                composition = json.load(f)\n            \n            # Load the composition into the generator\n            self.current_structure = composition[\"structure\"]\n            self.current_phrases = composition[\"phrases\"]\n            self.current_notes = composition[\"notes\"]\n            \n            # Load rhythm and chord data if available\n            if \"rhythm_patterns\" in composition:\n                self.current_rhythm_patterns = composition[\"rhythm_patterns\"]\n            if \"chord_progressions\" in composition:\n                self.current_chord_progressions = composition[\"chord_progressions\"]\n            \n            # Load parameters\n            params = composition.get(\"parameters\", {})\n            self.root_note = params.get(\"root_note\", self.root_note)\n            self.scale_type = params.get(\"scale_type\", self.scale_type)\n            self.bpm = params.get(\"bpm\", self.bpm)\n            \n            print(f\"Composition loaded from {filename}\")\n            return True\n        except Exception as e:\n            print(f\"Error loading composition: {e}\")\n            return False\n\n\n#============================================================\n# PART 2: DISPLAY TOKEN HIERARCHY (FOR TRAINING DATA)\n#============================================================\n\ndef display_token_hierarchy(generator):\n   \"\"\"Display the complete token hierarchy of a generated composition.\"\"\"\n   try:\n       print(\"===== HIERARCHICAL TOKEN STRUCTURE =====\\n\")\n       \n       # Level 1: Structure Tokens\n       print(\"STRUCTURE TOKENS:\")\n       structure_tokens = generator.current_structure\n       print(\" \".join(structure_tokens))\n       print()\n       \n       # Level 2: Phrase Tokens (grouped by structure)\n       print(\"PHRASE TOKENS (by structure):\")\n       for struct in structure_tokens:\n           phrases = generator.current_phrases.get(struct, [])\n           print(f\"{struct}: {' '.join(phrases)}\")\n       print()\n       \n       # Flatten all phrases into a sequence\n       all_phrases = []\n       for struct in structure_tokens:\n           all_phrases.extend(generator.current_phrases.get(struct, []))\n       \n       print(\"COMPLETE PHRASE SEQUENCE:\")\n       print(\" \".join(all_phrases))\n       print()\n       \n       # Level 3: Note Tokens (grouped by phrase)\n       print(\"NOTE TOKENS (by phrase):\")\n       for phrase in all_phrases:\n           notes = generator.current_notes.get(phrase, [])\n           # Convert MIDI numbers to strings for consistent representation\n           note_tokens = [str(n) if isinstance(n, int) else n for n in notes]\n           note_tokens = [str(n) if isinstance(n, int) else n for n in notes]\n           print(f\"{phrase}: {' '.join(note_tokens)}\")\n       print()\n       \n       # Flatten all notes into a sequence\n       all_notes = []\n       for phrase in all_phrases:\n           all_notes.extend([str(n) if isinstance(n, int) else n for n in generator.current_notes.get(phrase, [])])\n       \n       print(\"COMPLETE NOTE SEQUENCE:\")\n       print(\" \".join(all_notes))\n       \n       # Bonus: Show additional token information\n       print(\"\\n===== ADDITIONAL TOKEN INFORMATION =====\\n\")\n       \n       print(\"RHYTHM PATTERNS (by phrase):\")\n       for phrase in all_phrases:\n           if phrase in generator.current_rhythm_patterns:\n               patterns = generator.current_rhythm_patterns[phrase]\n               pattern_strs = [\" \".join(map(str, pattern)) for pattern in patterns]\n               print(f\"{phrase}: {pattern_strs}\")\n       \n       print(\"\\nCHORD PROGRESSIONS (by structure):\")\n       for struct in structure_tokens:\n           if struct in generator.current_chord_progressions:\n               progressions = generator.current_chord_progressions[struct]\n               progression_strs = [\" \".join(map(str, prog)) for prog in progressions]\n               print(f\"{struct}: {progression_strs}\")\n   except Exception as e:\n       print(f\"Error displaying token hierarchy: {e}\")\n\n\n#============================================================\n# PART 3: DATASET GENERATION FOR TRAINING\n#============================================================\n\ndef generate_training_dataset(generator, num_samples=1000, output_dir=\"music_dataset\", verbose=False):\n    \"\"\"Generate a dataset of music samples for training our hierarchical model.\"\"\"\n    try:\n        os.makedirs(output_dir, exist_ok=True)\n        \n        # Parameters to vary for diversity\n        root_notes = [48, 50, 52, 53, 55, 57, 59, 60, 62, 64, 65, 67]  # C3 to G4\n        scales = ['major', 'minor', 'pentatonic', 'blues']\n        temps = [0.5, 0.7, 0.9, 1.1]  # Various temperatures\n        \n        # Create dataset containers\n        structure_sequences = []\n        phrase_sequences = []\n        note_sequences = []\n        \n        # Store the original print function\n        original_print = print\n        \n        # Define a function to conditionally print based on verbose flag\n        def conditional_print(*args, **kwargs):\n            if verbose:\n                original_print(*args, **kwargs)\n        \n        # Generate samples\n        print(f\"Generating {num_samples} training samples...\")\n        try:\n            # Replace the global print function if not verbose\n            if not verbose:\n                import builtins\n                builtins.print = conditional_print\n            \n            for i in tqdm(range(num_samples)):\n                # Vary parameters\n                generator.root_note = root_notes[i % len(root_notes)]\n                generator.scale_type = scales[(i // len(root_notes)) % len(scales)]\n                temp = temps[(i // (len(root_notes) * len(scales))) % len(temps)]\n                generator.structure_temperature = temp\n                generator.phrase_temperature = temp\n                \n                # Reset the generator state\n                generator.current_structure = []\n                generator.current_phrases = {}\n                generator.current_notes = {}\n                generator.current_rhythm_patterns = {}\n                generator.current_chord_progressions = {}\n                \n                # Generate a composition (output will be suppressed if not verbose)\n                generator.generate_full_composition()\n                \n                # Process structure tokens\n                structure_tokens = [\"START\"] + generator.current_structure + [\"EOM\"]\n                structure_ids = [structure_to_id[token] for token in structure_tokens]\n                structure_sequences.append(structure_ids)\n                \n                # Process phrase tokens for each structure\n                for struct in generator.current_structure:\n                    struct_id = structure_to_id[struct]\n                    phrases = generator.current_phrases.get(struct, [])\n                    \n                    if phrases:\n                        phrase_tokens = [\"START\"] + phrases + [\"EOM\"]\n                        phrase_ids = [phrase_to_id[token] for token in phrase_tokens]\n                        \n                        # Create input-target pairs for phrase prediction\n                        phrase_sequence = {\n                            \"structure_id\": struct_id,\n                            \"phrase_ids\": phrase_ids\n                        }\n                        phrase_sequences.append(phrase_sequence)\n                \n                # Process note tokens for each phrase\n                for struct in generator.current_structure:\n                    struct_id = structure_to_id[struct]\n                    phrases = generator.current_phrases.get(struct, [])\n                    \n                    for phrase in phrases:\n                        phrase_id = phrase_to_id[phrase]\n                        notes = generator.current_notes.get(phrase, [])\n                        \n                        if notes:\n                            # Convert notes to string tokens and add START/EOM\n                            note_tokens = [\"START\"] + [str(n) if isinstance(n, int) else n for n in notes] + [\"EOM\"]\n                            note_ids = []\n                            \n                            for token in note_tokens:\n                                if token in note_to_id:\n                                    note_ids.append(note_to_id[token])\n                                elif token.isdigit() and int(token) in range(36, 85):\n                                    # Handle MIDI notes\n                                    note_ids.append(note_to_id[token])\n                                else:\n                                    # Skip unknown tokens\n                                    continue\n                            \n                            if len(note_ids) > 2:  # Ensure we have more than just START and EOM\n                                note_sequence = {\n                                    \"structure_id\": struct_id,\n                                    \"phrase_id\": phrase_id,\n                                    \"note_ids\": note_ids\n                                }\n                                note_sequences.append(note_sequence)\n                \n                # Save individual sample\n                sample_data = {\n                    \"structure\": generator.current_structure,\n                    \"phrases\": {k: v for k, v in generator.current_phrases.items()},\n                    \"notes\": {k: [str(n) if isinstance(n, int) else n for n in v] \n                             for k, v in generator.current_notes.items()},\n                    \"parameters\": {\n                        \"root_note\": generator.root_note,\n                        \"scale_type\": generator.scale_type\n                    }\n                }\n                \n                # Save with error handling\n                try:\n                    sample_path = os.path.join(output_dir, f\"sample_{i:04d}.json\")\n                    with open(sample_path, 'w') as f:\n                        json.dump(sample_data, f, indent=2)\n                except Exception as e:\n                    print(f\"Warning: Could not save sample_{i:04d}.json: {e}\")\n                \n                # Provide progress updates for long runs\n                if (i + 1) % 10 == 0:\n                    original_print(f\"Generated {i + 1}/{num_samples} samples\")\n        \n        finally:\n            # Restore the original print function\n            if not verbose:\n                builtins.print = original_print\n        \n        # Save all sequence data\n        dataset = {\n            \"structure_sequences\": structure_sequences,\n            \"phrase_sequences\": phrase_sequences,\n            \"note_sequences\": note_sequences\n        }\n        \n        # Save with error handling\n        try:\n            dataset_path = os.path.join(output_dir, \"all_sequences.pkl\")\n            with open(dataset_path, 'wb') as f:\n                pickle.dump(dataset, f)\n        except Exception as e:\n            print(f\"Warning: Could not save all_sequences.pkl: {e}\")\n            try:\n                with open(os.path.join(output_dir, \"all_sequences.json\"), 'w') as f:\n                    # Convert numpy arrays to lists for JSON serialization\n                    json.dump({\n                        \"structure_sequences\": [list(map(int, seq)) for seq in structure_sequences],\n                        \"phrase_sequences\": [{\n                            \"structure_id\": int(seq[\"structure_id\"]),\n                            \"phrase_ids\": list(map(int, seq[\"phrase_ids\"]))\n                        } for seq in phrase_sequences],\n                        \"note_sequences\": [{\n                            \"structure_id\": int(seq[\"structure_id\"]),\n                            \"phrase_id\": int(seq[\"phrase_id\"]),\n                            \"note_ids\": list(map(int, seq[\"note_ids\"]))\n                        } for seq in note_sequences]\n                    }, f)\n                print(\"Saved dataset as JSON instead\")\n            except Exception as e2:\n                print(f\"Could not save dataset in JSON either: {e2}\")\n        \n        print(f\"Generated {len(structure_sequences)} structure sequences\")\n        print(f\"Generated {len(phrase_sequences)} phrase sequences\")\n        print(f\"Generated {len(note_sequences)} note sequences\")\n        \n        return dataset\n    except Exception as e:\n        print(f\"Error generating dataset: {e}\")\n        traceback.print_exc()\n        # Return a minimal dataset to allow the pipeline to continue\n        return {\n            \"structure_sequences\": [],\n            \"phrase_sequences\": [],\n            \"note_sequences\": []\n        }\n\n\n#============================================================\n# PART 4: DATA PREPARATION FOR TRAINING\n#============================================================\n\ndef prepare_structure_data(structure_sequences):\n    \"\"\"Prepare structure sequence data for training.\"\"\"\n    try:\n        inputs = []\n        targets = []\n        \n        for sequence in structure_sequences:\n            # Create input-target pairs (predicting the next token)\n            for i in range(1, len(sequence)):\n                inputs.append(sequence[:i])\n                targets.append(sequence[i])\n        \n        # Pad inputs to max length\n        max_length = max(len(seq) for seq in inputs) if inputs else 1\n        padded_inputs = []\n        \n        for seq in inputs:\n            padded = seq + [0] * (max_length - len(seq))\n            padded_inputs.append(padded)\n        \n        return np.array(padded_inputs), np.array(targets)\n    except Exception as e:\n        print(f\"Error preparing structure data: {e}\")\n        # Return minimal dummy data\n        return np.array([[0]]), np.array([0])\n\ndef prepare_phrase_data(phrase_sequences):\n    \"\"\"Prepare phrase sequence data for training.\"\"\"\n    try:\n        structure_inputs = []\n        phrase_inputs = []\n        targets = []\n        \n        for sequence in phrase_sequences:\n            structure_id = sequence[\"structure_id\"]\n            phrase_ids = sequence[\"phrase_ids\"]\n            \n            # Create input-target pairs\n            for i in range(1, len(phrase_ids)):\n                structure_inputs.append(structure_id)\n                phrase_inputs.append(phrase_ids[:i])\n                targets.append(phrase_ids[i])\n        \n        # Pad phrase inputs\n        max_length = max(len(seq) for seq in phrase_inputs) if phrase_inputs else 1\n        padded_phrase_inputs = []\n        \n        for seq in phrase_inputs:\n            padded = seq + [0] * (max_length - len(seq))\n            padded_phrase_inputs.append(padded)\n        \n        return np.array(structure_inputs), np.array(padded_phrase_inputs), np.array(targets)\n    except Exception as e:\n        print(f\"Error preparing phrase data: {e}\")\n        # Return minimal dummy data\n        return np.array([0]), np.array([[0]]), np.array([0])\n\ndef prepare_note_data(note_sequences):\n    \"\"\"Prepare note sequence data for training.\"\"\"\n    try:\n        structure_inputs = []\n        phrase_inputs = []\n        note_inputs = []\n        targets = []\n        \n        for sequence in note_sequences:\n            structure_id = sequence[\"structure_id\"]\n            phrase_id = sequence[\"phrase_id\"]\n            note_ids = sequence[\"note_ids\"]\n            \n            # Create input-target pairs\n            for i in range(1, len(note_ids)):\n                structure_inputs.append(structure_id)\n                phrase_inputs.append(phrase_id)\n                note_inputs.append(note_ids[:i])\n                targets.append(note_ids[i])\n        \n        # Pad note inputs\n        max_length = max(len(seq) for seq in note_inputs) if note_inputs else 1\n        padded_note_inputs = []\n        \n        for seq in note_inputs:\n            padded = seq + [0] * (max_length - len(seq))\n            padded_note_inputs.append(padded)\n        \n        return np.array(structure_inputs), np.array(phrase_inputs), np.array(padded_note_inputs), np.array(targets)\n    except Exception as e:\n        print(f\"Error preparing note data: {e}\")\n        # Return minimal dummy data\n        return np.array([0]), np.array([0]), np.array([[0]]), np.array([0])\n\n\n#============================================================\n# PART 5: MODEL BUILDING & TRAINING\n#============================================================\n\ndef build_structure_model(vocab_size, embedding_dim=64, rnn_units=256):\n    \"\"\"Build a model for generating structure tokens.\"\"\"\n    try:\n        # Use a more robust architecture with attention\n        inputs = keras.layers.Input(shape=(None,))\n        embedding = keras.layers.Embedding(vocab_size, embedding_dim)(inputs)\n        \n        # First LSTM layer with return sequences\n        lstm1 = keras.layers.LSTM(rnn_units, return_sequences=True)(embedding)\n        dropout1 = keras.layers.Dropout(0.2)(lstm1)\n        \n        # Self-attention layer for better long-range dependencies\n        attention = keras.layers.MultiHeadAttention(\n            num_heads=4, key_dim=rnn_units // 4)(dropout1, dropout1)\n        attention_add = keras.layers.Add()([dropout1, attention])\n        attention_norm = keras.layers.LayerNormalization()(attention_add)\n        \n        # Second LSTM layer\n        lstm2 = keras.layers.LSTM(rnn_units)(attention_norm)\n        dropout2 = keras.layers.Dropout(0.2)(lstm2)\n        \n        # Output layer\n        outputs = keras.layers.Dense(vocab_size)(dropout2)\n        \n        # Create model\n        model = keras.Model(inputs=inputs, outputs=outputs)\n        \n        # Compile model\n        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n        model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n        \n        return model\n    except Exception as e:\n        print(f\"Error building structure model: {e}\")\n        # Return a minimal model\n        model = keras.Sequential([\n            keras.layers.InputLayer(shape=(None,)),\n            keras.layers.Embedding(vocab_size, embedding_dim),\n            keras.layers.LSTM(rnn_units),\n            keras.layers.Dense(vocab_size)\n        ])\n        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n        model.compile(optimizer='adam', loss=loss)\n        return model\n\ndef build_phrase_model(structure_vocab_size, phrase_vocab_size, embedding_dim=64, rnn_units=256):\n    \"\"\"Build a model for generating phrase tokens conditioned on structure.\"\"\"\n    try:\n        # Structure input\n        structure_input = keras.layers.Input(shape=(1,))\n        structure_embedding = keras.layers.Embedding(structure_vocab_size, embedding_dim)(structure_input)\n        structure_embedding = keras.layers.Flatten()(structure_embedding)\n        \n        # Phrase sequence input\n        phrase_input = keras.layers.Input(shape=(None,))\n        phrase_embedding = keras.layers.Embedding(phrase_vocab_size, embedding_dim)(phrase_input)\n        \n        # Create initial state from structure embedding\n        structure_state_h = keras.layers.Dense(rnn_units)(structure_embedding)\n        structure_state_c = keras.layers.Dense(rnn_units)(structure_embedding)\n        initial_state = [structure_state_h, structure_state_c]\n        \n        # Process phrases with LSTM, using structure as initial state\n        lstm1 = keras.layers.LSTM(rnn_units, return_sequences=True, \n                                return_state=False)(phrase_embedding, initial_state=initial_state)\n        dropout1 = keras.layers.Dropout(0.2)(lstm1)\n        \n        # Add attention mechanism for better conditioning\n        attention = keras.layers.MultiHeadAttention(\n            num_heads=4, key_dim=rnn_units // 4)(dropout1, dropout1)\n        attention_add = keras.layers.Add()([dropout1, attention])\n        attention_norm = keras.layers.LayerNormalization()(attention_add)\n        \n        # Another LSTM layer\n        lstm2 = keras.layers.LSTM(rnn_units)(attention_norm)\n        dropout2 = keras.layers.Dropout(0.2)(lstm2)\n        \n        # Output layer\n        output = keras.layers.Dense(phrase_vocab_size)(dropout2)\n        \n        # Create and compile model\n        model = keras.Model(inputs=[structure_input, phrase_input], outputs=output)\n        \n        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n        model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n        \n        return model\n    except Exception as e:\n        print(f\"Error building phrase model: {e}\")\n        # Return a minimal model\n        # Structure input\n        structure_input = keras.layers.Input(shape=(1,))\n        structure_embedding = keras.layers.Embedding(structure_vocab_size, embedding_dim)(structure_input)\n        structure_embedding = keras.layers.Flatten()(structure_embedding)\n        \n        # Phrase sequence input\n        phrase_input = keras.layers.Input(shape=(None,))\n        phrase_embedding = keras.layers.Embedding(phrase_vocab_size, embedding_dim)(phrase_input)\n        \n        # Simple LSTM\n        lstm = keras.layers.LSTM(rnn_units)(phrase_embedding)\n        \n        # Combine with structure\n        combined = keras.layers.Concatenate()([structure_embedding, lstm])\n        \n        # Output layer\n        output = keras.layers.Dense(phrase_vocab_size)(combined)\n        \n        # Create and compile model\n        model = keras.Model(inputs=[structure_input, phrase_input], outputs=output)\n        \n        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n        model.compile(optimizer='adam', loss=loss)\n        \n        return model\n\ndef build_note_model(structure_vocab_size, phrase_vocab_size, note_vocab_size, \n                    embedding_dim=64, rnn_units=256):\n    \"\"\"Build a model for generating note tokens conditioned on structure and phrase.\"\"\"\n    try:\n        # Structure input\n        structure_input = keras.layers.Input(shape=(1,))\n        structure_embedding = keras.layers.Embedding(structure_vocab_size, embedding_dim)(structure_input)\n        structure_embedding = keras.layers.Flatten()(structure_embedding)\n        \n        # Phrase input\n        phrase_input = keras.layers.Input(shape=(1,))\n        phrase_embedding = keras.layers.Embedding(phrase_vocab_size, embedding_dim)(phrase_input)\n        phrase_embedding = keras.layers.Flatten()(phrase_embedding)\n        \n        # Combine structure and phrase embeddings\n        context = keras.layers.Concatenate()([structure_embedding, phrase_embedding])\n        context_dense = keras.layers.Dense(embedding_dim, activation='relu')(context)\n        \n        # Note sequence input\n        note_input = keras.layers.Input(shape=(None,))\n        note_embedding = keras.layers.Embedding(note_vocab_size, embedding_dim)(note_input)\n        \n        # Create initial state from context\n        context_state_h = keras.layers.Dense(rnn_units)(context_dense)\n        context_state_c = keras.layers.Dense(rnn_units)(context_dense)\n        initial_state = [context_state_h, context_state_c]\n        \n        # Process notes with LSTM, using context as initial state\n        lstm1 = keras.layers.LSTM(rnn_units, return_sequences=True, \n                                return_state=False)(note_embedding, initial_state=initial_state)\n        dropout1 = keras.layers.Dropout(0.2)(lstm1)\n        \n        # Add attention mechanism\n        attention = keras.layers.MultiHeadAttention(\n            num_heads=4, key_dim=rnn_units // 4)(dropout1, dropout1)\n        attention_add = keras.layers.Add()([dropout1, attention])\n        attention_norm = keras.layers.LayerNormalization()(attention_add)\n        \n        # Another LSTM layer\n        lstm2 = keras.layers.LSTM(rnn_units)(attention_norm)\n        dropout2 = keras.layers.Dropout(0.2)(lstm2)\n        \n        # Output layer\n        output = keras.layers.Dense(note_vocab_size)(dropout2)\n        \n        # Create and compile model\n        model = keras.Model(inputs=[structure_input, phrase_input, note_input], outputs=output)\n        \n        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n        model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n        \n        return model\n    except Exception as e:\n        print(f\"Error building note model: {e}\")\n        # Return a minimal model\n        structure_input = keras.layers.Input(shape=(1,))\n        phrase_input = keras.layers.Input(shape=(1,))\n        note_input = keras.layers.Input(shape=(None,))\n        \n        # Simple embeddings\n        structure_embedding = keras.layers.Embedding(structure_vocab_size, embedding_dim)(structure_input)\n        structure_embedding = keras.layers.Flatten()(structure_embedding)\n        \n        phrase_embedding = keras.layers.Embedding(phrase_vocab_size, embedding_dim)(phrase_input)\n        phrase_embedding = keras.layers.Flatten()(phrase_embedding)\n        \n        note_embedding = keras.layers.Embedding(note_vocab_size, embedding_dim)(note_input)\n        \n        # Simple LSTM\n        lstm = keras.layers.LSTM(rnn_units)(note_embedding)\n        \n        # Combine all\n        combined = keras.layers.Concatenate()([structure_embedding, phrase_embedding, lstm])\n        \n        # Output layer\n        output = keras.layers.Dense(note_vocab_size)(combined)\n        \n        # Create and compile model\n        model = keras.Model(inputs=[structure_input, phrase_input, note_input], outputs=output)\n        \n        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n        model.compile(optimizer='adam', loss=loss)\n        \n        return model\n\ndef train_hierarchical_models(dataset, model_dir=\"music_models\", epochs=10, batch_size=64):\n    \"\"\"Train all three hierarchical models.\"\"\"\n    try:\n        # Make sure model directory exists\n        os.makedirs(model_dir, exist_ok=True)\n        \n        # Extract sequence data\n        structure_sequences = dataset[\"structure_sequences\"]\n        phrase_sequences = dataset[\"phrase_sequences\"]\n        note_sequences = dataset[\"note_sequences\"]\n        \n        # Check for empty datasets\n        if not structure_sequences or not phrase_sequences or not note_sequences:\n            print(\"Warning: One or more sequence types is empty. Training may fail.\")\n            \n            # Create minimal dummy data if needed\n            if not structure_sequences:\n                structure_sequences = [np.array([0, 1, 2])]\n            if not phrase_sequences:\n                phrase_sequences = [{\"structure_id\": 0, \"phrase_ids\": np.array([0, 1, 2])}]\n            if not note_sequences:\n                note_sequences = [{\"structure_id\": 0, \"phrase_id\": 0, \"note_ids\": np.array([0, 1, 2])}]\n        \n        # Prepare data for training\n        print(\"Preparing structure data...\")\n        structure_inputs, structure_targets = prepare_structure_data(structure_sequences)\n        \n        print(\"Preparing phrase data...\")\n        phrase_structure_inputs, phrase_inputs, phrase_targets = prepare_phrase_data(phrase_sequences)\n        \n        print(\"Preparing note data...\")\n        note_structure_inputs, note_phrase_inputs, note_inputs, note_targets = prepare_note_data(note_sequences)\n        \n        # Create model directory\n        try:\n            os.makedirs(model_dir, exist_ok=True)\n        except Exception as e:\n            print(f\"Warning: Could not create model directory: {e}\")\n            model_dir = \".\"  # Use current directory as fallback\n        \n        # Build models\n        print(\"Building structure model...\")\n        structure_model = build_structure_model(structure_vocab_size)\n        \n        print(\"Building phrase model...\")\n        phrase_model = build_phrase_model(structure_vocab_size, phrase_vocab_size)\n        \n        print(\"Building note model...\")\n        note_model = build_note_model(structure_vocab_size, phrase_vocab_size, note_vocab_size)\n        \n        # Prepare callbacks for early stopping\n        early_stopping = keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n        \n        # Train structure model\n        print(\"Training structure model...\")\n        try:\n            # Use try/except for each model to continue even if one fails\n            structure_history = structure_model.fit(\n                structure_inputs, structure_targets,\n                batch_size=batch_size,\n                epochs=epochs,\n                validation_split=0.1,\n                callbacks=[early_stopping]\n            )\n            structure_model.save(os.path.join(model_dir, \"structure_model.keras\"))\n            print(\"Structure model saved.\")\n        except Exception as e:\n            print(f\"Error training structure model: {e}\")\n            structure_history = None\n        \n        # Train phrase model\n        print(\"Training phrase model...\")\n        try:\n            phrase_history = phrase_model.fit(\n                [phrase_structure_inputs, phrase_inputs], phrase_targets,\n                batch_size=batch_size,\n                epochs=epochs,\n                validation_split=0.1,\n                callbacks=[early_stopping]\n            )\n            phrase_model.save(os.path.join(model_dir, \"phrase_model.keras\"))\n            print(\"Phrase model saved.\")\n        except Exception as e:\n            print(f\"Error training phrase model: {e}\")\n            phrase_history = None\n        \n        # Train note model\n        print(\"Training note model...\")\n        try:\n            note_history = note_model.fit(\n                [note_structure_inputs, note_phrase_inputs, note_inputs], note_targets,\n                batch_size=batch_size,\n                epochs=epochs,\n                validation_split=0.1,\n                callbacks=[early_stopping]\n            )\n            note_model.save(os.path.join(model_dir, \"note_model.keras\"))\n            print(\"Note model saved.\")\n        except Exception as e:\n            print(f\"Error training note model: {e}\")\n            note_history = None\n        \n        # Plot training history\n        try:\n            plt.figure(figsize=(15, 5))\n            \n            plt.subplot(1, 3, 1)\n            if structure_history:\n                plt.plot(structure_history.history['loss'])\n                if 'val_loss' in structure_history.history:\n                    plt.plot(structure_history.history['val_loss'])\n                plt.title('Structure Model Loss')\n                plt.ylabel('Loss')\n                plt.xlabel('Epoch')\n                plt.legend(['Train', 'Validation'])\n            else:\n                plt.title('Structure Model (Training Failed)')\n            \n            plt.subplot(1, 3, 2)\n            if phrase_history:\n                plt.plot(phrase_history.history['loss'])\n                if 'val_loss' in phrase_history.history:\n                    plt.plot(phrase_history.history['val_loss'])\n                plt.title('Phrase Model Loss')\n                plt.ylabel('Loss')\n                plt.xlabel('Epoch')\n                plt.legend(['Train', 'Validation'])\n            else:\n                plt.title('Phrase Model (Training Failed)')\n            \n            plt.subplot(1, 3, 3)\n            if note_history:\n                plt.plot(note_history.history['loss'])\n                if 'val_loss' in note_history.history:\n                    plt.plot(note_history.history['val_loss'])\n                plt.title('Note Model Loss')\n                plt.ylabel('Loss')\n                plt.xlabel('Epoch')\n                plt.legend(['Train', 'Validation'])\n            else:\n                plt.title('Note Model (Training Failed)')\n            \n            plt.tight_layout()\n            plt.savefig(os.path.join(model_dir, \"training_history.png\"))\n            plt.show()\n        except Exception as e:\n            print(f\"Error plotting training history: {e}\")\n        \n        print(f\"Models saved to {model_dir}\")\n        \n        return {\n            \"structure_model\": structure_model,\n            \"phrase_model\": phrase_model,\n            \"note_model\": note_model\n        }\n    except Exception as e:\n        print(f\"Error in train_hierarchical_models: {e}\")\n        traceback.print_exc()\n        # Return empty models\n        return {\n            \"structure_model\": None,\n            \"phrase_model\": None,\n            \"note_model\": None\n        }\n\n\n#============================================================\n# PART 6: MUSIC GENERATION USING TRAINED MODELS\n#============================================================\n\ndef sample_from_logits(logits, temperature=1.0):\n    \"\"\"Sample from logits with temperature adjustment.\"\"\"\n    try:\n        logits = logits / temperature\n        # Convert from logits to probabilities\n        probs = tf.nn.softmax(logits).numpy()\n        # Sample from the distribution\n        return np.random.choice(len(probs), p=probs)\n    except Exception as e:\n        print(f\"Error sampling from logits: {e}\")\n        # Return a random index as fallback\n        return np.random.randint(0, len(logits))\n\ndef generate_structure(model, max_length=10, temperature=0.8):\n    \"\"\"Generate a sequence of structure tokens.\"\"\"\n    try:\n        # Start with the START token\n        input_ids = np.array([[structure_to_id[\"START\"]]])\n        structure_tokens = []\n        \n        for _ in range(max_length):\n            predictions = model.predict(input_ids, verbose=0)\n            predicted_id = sample_from_logits(predictions[0], temperature)\n            \n            # Convert ID back to token\n            predicted_token = id_to_structure[predicted_id]\n            \n            if predicted_token == \"EOM\":\n                break\n                \n            structure_tokens.append(predicted_token)\n            \n            # Update input for next prediction\n            input_ids = np.array([[predicted_id]])\n        \n        # Ensure we have at least one structure element\n        if not structure_tokens:\n            print(\"Generated empty structure. Using default.\")\n            structure_tokens = [\"verse\"]\n            \n        return structure_tokens\n    except Exception as e:\n        print(f\"Error generating structure: {e}\")\n        # Return a default structure\n        return [\"intro\", \"verse\", \"chorus\", \"outro\"]\n\ndef generate_phrases(model, structure_token, max_phrases=4, temperature=0.7):\n    \"\"\"Generate phrases for a given structure token.\"\"\"\n    try:\n        # Convert structure token to ID\n        structure_id = structure_to_id[structure_token]\n        structure_input = np.array([[structure_id]])\n        \n        # Start with the START token\n        phrase_input = np.array([[phrase_to_id[\"START\"]]])\n        phrase_tokens = []\n        \n        for _ in range(max_phrases):\n            predictions = model.predict([structure_input, phrase_input], verbose=0)\n            predicted_id = sample_from_logits(predictions[0], temperature)\n            \n            # Convert ID back to token\n            predicted_token = id_to_phrase[predicted_id]\n            \n            if predicted_token == \"EOM\":\n                break\n                \n            phrase_tokens.append(predicted_token)\n            \n            # Update input for next prediction\n            phrase_input = np.array([[predicted_id]])\n        \n        # Ensure we have at least one phrase\n        if not phrase_tokens:\n            print(f\"Generated empty phrases for {structure_token}. Using default.\")\n            phrase_tokens = [\"rhythmic\"]\n            \n        return phrase_tokens\n    except Exception as e:\n        print(f\"Error generating phrases: {e}\")\n        # Return default phrases\n        return [\"rhythmic\"]\n\ndef generate_notes(model, structure_token, phrase_token, max_notes=16, temperature=0.5):\n    \"\"\"Generate notes for a given structure and phrase token.\"\"\"\n    try:\n        # Convert tokens to IDs\n        structure_id = structure_to_id[structure_token]\n        phrase_id = phrase_to_id[phrase_token]\n        \n        structure_input = np.array([[structure_id]])\n        phrase_input = np.array([[phrase_id]])\n        \n        # Start with the START token\n        note_input = np.array([[note_to_id[\"START\"]]])\n        note_tokens = []\n        \n        for _ in range(max_notes):\n            predictions = model.predict([structure_input, phrase_input, note_input], verbose=0)\n            predicted_id = sample_from_logits(predictions[0], temperature)\n            \n            # Convert ID back to token\n            predicted_token = id_to_note[predicted_id]\n            \n            if predicted_token == \"EOM\":\n                break\n                \n            note_tokens.append(predicted_token)\n            \n            # Update input for next prediction\n            note_input = np.array([[predicted_id]])\n        \n        # Ensure we have at least one note\n        if not note_tokens:\n            print(f\"Generated empty notes for {phrase_token}. Using default.\")\n            note_tokens = [\"60\"]  # Middle C\n            \n        return note_tokens\n    except Exception as e:\n        print(f\"Error generating notes: {e}\")\n        # Return default notes\n        return [\"60\", \"62\", \"64\", \"65\", \"67\"]\n\ndef generate_composition(models, temperature_dict=None):\n    \"\"\"Generate a full musical composition using the hierarchical models.\"\"\"\n    try:\n        if temperature_dict is None:\n            temperature_dict = {\n                \"structure\": 0.8,\n                \"phrase\": 0.7,\n                \"note\": 0.5\n            }\n        \n        structure_model = models[\"structure_model\"]\n        phrase_model = models[\"phrase_model\"]\n        note_model = models[\"note_model\"]\n        \n        # Check if models are valid\n        if structure_model is None or phrase_model is None or note_model is None:\n            print(\"One or more models are missing. Using fallback generation.\")\n            # Create a generator to use rule-based generation instead\n            generator = HierarchicalMusicGenerator()\n            composition = generator.generate_full_composition()\n            return {\n                \"structure\": generator.current_structure,\n                \"phrases\": generator.current_phrases,\n                \"notes\": generator.current_notes\n            }\n        \n        # Generate structure sequence\n        structure_tokens = generate_structure(structure_model, temperature=temperature_dict[\"structure\"])\n        \n        print(f\"Generated structure: {structure_tokens}\")\n        \n        # Generate phrases for each structure\n        all_phrases = {}\n        for structure_token in structure_tokens:\n            phrases = generate_phrases(phrase_model, structure_token, temperature=temperature_dict[\"phrase\"])\n            all_phrases[structure_token] = phrases\n            print(f\"  {structure_token} phrases: {phrases}\")\n        \n        # Generate notes for each phrase\n        all_notes = {}\n        for structure_token, phrases in all_phrases.items():\n            for phrase_token in phrases:\n                notes = generate_notes(\n                    note_model,\n                    structure_token,\n                    phrase_token,\n                    temperature=temperature_dict[\"note\"]\n                )\n                \n                all_notes[phrase_token] = notes\n                print(f\"    {phrase_token} notes: {notes}\")\n        \n        # Create the hierarchical composition\n        composition = {\n            \"structure\": structure_tokens,\n            \"phrases\": all_phrases, \n            \"notes\": all_notes \n        }\n        \n        return composition\n    except Exception as e:\n        print(f\"Error generating composition: {e}\")\n        traceback.print_exc()\n        # Fallback to rule-based generation\n        print(\"Falling back to rule-based composition.\")\n        generator = HierarchicalMusicGenerator()\n        generator.generate_full_composition()\n        return {\n            \"structure\": generator.current_structure,\n            \"phrases\": generator.current_phrases,\n            \"notes\": generator.current_notes\n        }\n\ndef convert_note_token_to_midi(note_token):\n    \"\"\"Convert a note token to a MIDI note number.\"\"\"\n    try:\n        if isinstance(note_token, int):\n            return note_token\n        elif note_token.isdigit():\n            return int(note_token)\n        else:\n            return None  # For non-numeric tokens like \"EOM\"\n    except Exception as e:\n        print(f\"Error converting note token: {e}\")\n        return 60  # Default to middle C\n\ndef composition_to_midi(composition, output_file=\"generated_composition.mid\", bpm=120):\n    \"\"\"Convert a generated composition to a MIDI file.\"\"\"\n    if not PRETTY_MIDI_AVAILABLE:\n        print(\"pretty_midi is required to create MIDI files.\")\n        return None\n    \n    try:\n        # Create a PrettyMIDI object\n        midi = pretty_midi.PrettyMIDI(initial_tempo=bpm)\n        \n        # Create a piano instrument\n        piano = pretty_midi.Instrument(program=0)  # Piano\n        \n        # Track timing\n        current_time = 0.0\n        seconds_per_beat = 60.0 / bpm\n        \n        # Process each structure element\n        for structure_token in composition[\"structure\"]:\n            # Get phrases for this structure\n            structure_phrases = composition[\"phrases\"].get(structure_token, [])\n            \n            for phrase_token in structure_phrases:\n                # Get notes for this phrase\n                phrase_notes = composition[\"notes\"].get(phrase_token, [])\n                \n                # Set duration based on phrase type\n                if phrase_token == \"sustained\":\n                    note_duration = seconds_per_beat * 2.0  # Longer notes\n                elif phrase_token == \"staccato\":\n                    note_duration = seconds_per_beat * 0.5  # Shorter notes\n                else:\n                    note_duration = seconds_per_beat  # Default duration\n                \n                # Add each note\n                for note_token in phrase_notes:\n                    midi_note = convert_note_token_to_midi(note_token)\n                    \n                    if midi_note is not None:\n                        # Create a MIDI note\n                        note = pretty_midi.Note(\n                            velocity=100, \n                            pitch=midi_note, \n                            start=current_time, \n                            end=current_time + note_duration\n                        )\n                        piano.notes.append(note)\n                    \n                    current_time += note_duration\n                \n                # Add a small pause between phrases\n                current_time += seconds_per_beat * 0.15\n            \n            # Add a larger pause between structure elements\n            current_time += seconds_per_beat\n        \n        # Add the instrument to the MIDI file\n        midi.instruments.append(piano)\n        \n        # Make sure the directory exists\n        dirname = os.path.dirname(output_file)\n        if dirname:\n            os.makedirs(dirname, exist_ok=True)\n        \n        # Save to file\n        midi.write(output_file)\n        print(f\"MIDI file saved to {output_file}\")\n        \n        return output_file\n    except Exception as e:\n        print(f\"Error creating MIDI file: {e}\")\n        traceback.print_exc()\n        return None\n\n\n#============================================================\n# PART 7: HELPER FUNCTIONS FOR AUDIO PLAYBACK\n#============================================================\n\ndef play_wav_file(filename):\n    \"\"\"Play a WAV file\"\"\"\n    try:\n        print(f\"Playing {filename}...\")\n        # Read the WAV file\n        sample_rate, audio_data = wavfile.read(filename)\n        \n        # Convert to float if needed\n        if audio_data.dtype == np.int16:\n            audio_data = audio_data.astype(np.float32) / 32767.0\n        elif audio_data.dtype == np.int32:\n            audio_data = audio_data.astype(np.float32) / 2147483647.0\n        \n        # Show waveform\n        plt.figure(figsize=(12, 3))\n        plt.plot(audio_data[:min(len(audio_data), 100000)])\n        plt.title(f\"Waveform: {filename}\")\n        plt.xlabel(\"Sample\")\n        plt.ylabel(\"Amplitude\")\n        plt.show()\n        \n        # Play audio\n        return Audio(audio_data, rate=sample_rate, autoplay=True)\n    except Exception as e:\n        print(f\"Error playing {filename}: {e}\")\n        # Return silent audio as fallback\n        return Audio(np.zeros(44100 * 2), rate=44100)\n\ndef play_composition(midi_filename):\n    \"\"\"Play a MIDI composition as audio with visualization at double speed\"\"\"\n    try:\n        # Use the already imported pretty_midi\n        if not PRETTY_MIDI_AVAILABLE:\n            print(\"pretty_midi is required to play MIDI files.\")\n            return None\n            \n        midi_data = pretty_midi.PrettyMIDI(midi_filename)\n        \n        # Print composition info\n        print(f\"Playing: {midi_filename}\")\n        print(f\"Duration (at 2x speed): {midi_data.get_end_time()/2:.2f} seconds\")\n        print(f\"Instruments: {len(midi_data.instruments)}, Notes: {sum(len(i.notes) for i in midi_data.instruments)}\")\n        \n        # Convert to audio\n        audio_data = midi_data.synthesize(fs=44100)\n        \n        # Normalize audio\n        if np.max(np.abs(audio_data)) > 0:\n            audio_data = audio_data / np.max(np.abs(audio_data)) * 0.9\n        \n        # Plot waveform\n        plt.figure(figsize=(12, 3))\n        plt.plot(audio_data[:min(len(audio_data), 100000)])\n        plt.title(f\"Audio Waveform: {midi_filename}\")\n        plt.xlabel(\"Sample\")\n        plt.ylabel(\"Amplitude\")\n        plt.grid(True, alpha=0.3)\n        plt.show()\n        \n        # Play audio at double speed\n        return Audio(audio_data, rate=44100 * 2, autoplay=True)\n    except Exception as e:\n        print(f\"Error playing composition: {e}\")\n        # Return silent audio as fallback\n        return Audio(np.zeros(44100), rate=44100 * 2)\n\ndef generate_short_demo():\n    \"\"\"Generate a shorter music demonstration that's easier to play in notebooks.\"\"\"\n    try:\n        # Create a new generator\n        generator = HierarchicalMusicGenerator()\n        generator.enhance_sine_wave()\n        \n        # Override to make a much shorter composition\n        # Limit to just 4 structure elements and fewer phrases\n        def short_generation():\n            # Generate just a short structure\n            generator.current_structure = [\"intro\", \"verse\", \"chorus\", \"outro\"]\n            print(f\"Generated structure: {generator.current_structure}\")\n            \n            # For each structure, generate chord progression and just 1-2 phrases\n            for struct in generator.current_structure:\n                # Generate chord progression\n                chord_progression = generator.generate_chord_progression(struct)\n                chord_names = [numeral_to_name(degree, generator.scale_type) for degree in chord_progression]\n                print(f\"  {struct} chord progression: {chord_names}\")\n                \n                num_phrases = random.randint(1, 2)\n                phrases = generator.generate_phrases(struct, num_phrases=num_phrases)\n                print(f\"  {struct} phrases: {phrases}\")\n                \n                # For each phrase, generate rhythm and notes\n                for phrase in phrases:\n                    # Generate rhythm pattern\n                    rhythm = generator.generate_rhythm_pattern(phrase)\n                    \n                    # Generate fewer notes\n                    notes = generator.generate_notes(phrase, num_notes=6)\n                    \n                    # Display notes (excluding EOM)\n                    note_names = []\n                    for n in notes[:-1]:\n                        try:\n                            note_names.append(generator.midi_to_note_name(n))\n                        except:\n                            note_names.append(str(n))\n                    print(f\"    {phrase} notes: {note_names}\")\n            \n            return {\n                \"structure\": generator.current_structure,\n                \"chord_progressions\": generator.current_chord_progressions,\n                \"phrases\": generator.current_phrases,\n                \"rhythm_patterns\": generator.current_rhythm_patterns,\n                \"notes\": generator.current_notes\n            }\n        \n        # Run the short generation\n        print(\"Generating short demo composition...\")\n        composition = short_generation()\n        \n        # Create MIDI\n        if PRETTY_MIDI_AVAILABLE:\n            midi_file = generator.create_midi(\"short_demo.mid\")\n            print(f\"MIDI file created: {midi_file}\")\n        \n        # Render audio\n        generator.render_audio()\n        \n        # Save the shorter audio file\n        wav_file = generator.save_audio(\"short_demo.wav\")\n        print(f\"Audio saved to: {wav_file}\")\n        \n        # Display token hierarchy\n        display_token_hierarchy(generator)\n        \n        # Try to play the audio directly\n        try:\n            audio_player = ipd.Audio(generator.audio_data, rate=generator.sample_rate, autoplay=True)\n            display(audio_player)\n        except Exception as e:\n            print(f\"Could not play audio directly: {e}\")\n        \n        # Also show the waveform for visualization\n        try:\n            plt.figure(figsize=(10, 3))\n            plt.plot(generator.audio_data)\n            plt.title(\"Audio Waveform\")\n            plt.show()\n        except Exception as e:\n            print(f\"Could not display waveform: {e}\")\n        \n        return generator\n    except Exception as e:\n        print(f\"Error in generate_short_demo: {e}\")\n        traceback.print_exc()\n        # Return a minimal generator\n        return HierarchicalMusicGenerator()\n\n\n#============================================================\n# PART 8: MAIN FUNCTION TO RUN THE PIPELINE\n#============================================================\n\ndef run_hierarchical_generator():\n    \"\"\"Run the hierarchical music generator with enhanced audio playback.\"\"\"\n    try:\n        print(\"Initializing Hierarchical Music Generator...\")\n        generator = HierarchicalMusicGenerator()\n        \n        # Enhance the sine wave generator for better sound\n        generator.enhance_sine_wave()\n        \n        # Generate a full composition\n        print(\"Generating full composition...\")\n        composition = generator.generate_full_composition()\n        \n        # Create MIDI\n        if PRETTY_MIDI_AVAILABLE:\n            print(\"Creating MIDI file...\")\n            midi_file = generator.create_midi()\n            print(f\"MIDI file created: {midi_file}\")\n        \n        # Render audio\n        print(\"Rendering audio...\")\n        generator.render_audio()\n        \n        # Display token hierarchy\n        display_token_hierarchy(generator)\n        \n        # Play audio with enhanced playback\n        print(\"Playing audio with enhanced playback:\")\n        generator.play_audio_fixed()\n        \n        # Visualize\n        print(\"Visualizing composition structure:\")\n        generator.visualize_composition().show()\n        \n        # Save composition\n        print(\"Saving composition...\")\n        json_file = generator.save_composition()\n        wav_file = generator.save_audio(\"composition.wav\")\n        print(f\"Composition saved to: {json_file} and {wav_file}\")\n        \n        return generator\n    except Exception as e:\n        print(f\"Error running hierarchical generator: {e}\")\n        traceback.print_exc()\n        return HierarchicalMusicGenerator()\n\ndef run_complete_pipeline(mode=\"quick_demo\"):\n    \"\"\"Run the entire hierarchical music generation pipeline with audio playback\n    \n    Parameters:\n        mode (str): One of \"quick_demo\", \"generate_data\", \"train\", \"generate\", \"custom\"\n    \"\"\"\n    try:\n        if mode == \"quick_demo\":\n            # Generate a quick demo with the rule-based generator\n            print(\"Generating rule-based demo...\")\n            generator = generate_short_demo()\n            \n            # Play the generated composition\n            if os.path.exists(\"short_demo.mid\"):\n                play_composition(\"short_demo.mid\")\n            \n            return generator\n        \n        elif mode == \"generate_data\":\n            # Generate training data\n            num_samples = 20\n            print(f\"Generating {num_samples} training samples...\")\n            \n            # Create generator\n            generator = HierarchicalMusicGenerator()\n            generator.enhance_sine_wave()\n            \n            # Create output directory\n            output_dir = \"improved_music_dataset\"\n            os.makedirs(output_dir, exist_ok=True)\n            \n            # Generate dataset\n            dataset = generate_training_dataset(generator, num_samples=num_samples, output_dir=output_dir)\n            \n            print(f\"Dataset generated in '{output_dir}'\")\n            return dataset\n            \n        elif mode == \"train\":\n            # Run a minimal training pipeline\n            print(\"Training hierarchical music generation models...\")\n            \n            # 1. Generate data if needed\n            if not os.path.exists(\"music_dataset\"):\n                print(\"Generating training data first...\")\n                dataset = generate_training_dataset(\n                    HierarchicalMusicGenerator().enhance_sine_wave(), \n                    num_samples=20, \n                    verbose=False\n                )\n            else:\n                # Load existing dataset\n                try:\n                    with open(os.path.join(\"music_dataset\", \"all_sequences.pkl\"), 'rb') as f:\n                        dataset = pickle.load(f)\n                    print(\"Loaded existing dataset.\")\n                except:\n                    print(\"Could not load existing dataset. Generating new data...\")\n                    dataset = generate_training_dataset(\n                        HierarchicalMusicGenerator().enhance_sine_wave(), \n                        num_samples=20, \n                        verbose=False\n                    )\n            \n            # 2. Train models\n            models = train_hierarchical_models(dataset, epochs=3, batch_size=32)\n            return models\n        \n        elif mode == \"generate\":\n            # Generate compositions using neural models\n            print(\"Generating neural model compositions...\")\n            \n            # Check if models exist\n            model_exists = all(os.path.exists(os.path.join(\"music_models\", f\"{m}_model.keras\")) \n                              for m in [\"structure\", \"phrase\", \"note\"])\n            \n            # Load or train models\n            if model_exists:\n                print(\"Loading existing models...\")\n                models = {\n                    \"structure_model\": keras.models.load_model(os.path.join(\"music_models\", \"structure_model.keras\")),\n                    \"phrase_model\": keras.models.load_model(os.path.join(\"music_models\", \"phrase_model.keras\")),\n                    \"note_model\": keras.models.load_model(os.path.join(\"music_models\", \"note_model.keras\"))\n                }\n            else:\n                print(\"No existing models found. Training new models...\")\n                # Run the training pipeline\n                models = run_complete_pipeline(\"train\")\n            \n            # Generate compositions with different temperatures\n            print(\"\\nGenerating standard composition...\")\n            composition = generate_composition(models)\n            midi_file = composition_to_midi(composition, \"standard_composition.mid\")\n            \n            print(\"\\nGenerating creative composition (higher temperature)...\")\n            creative_composition = generate_composition(models, {\n                \"structure\": 1.2,\n                \"phrase\": 1.0,\n                \"note\": 0.8\n            })\n            creative_midi = composition_to_midi(creative_composition, \"creative_composition.mid\")\n            \n            print(\"\\nGenerating conservative composition (lower temperature)...\")\n            conservative_composition = generate_composition(models, {\n                \"structure\": 0.6,\n                \"phrase\": 0.5,\n                \"note\": 0.4\n            })\n            conservative_midi = composition_to_midi(conservative_composition, \"conservative_composition.mid\")\n            \n            # Play the compositions\n            print(\"\\nPlaying standard composition:\")\n            play_composition(\"standard_composition.mid\")\n            \n            print(\"\\nPlaying creative composition:\")\n            play_composition(\"creative_composition.mid\")\n            \n            print(\"\\nPlaying conservative composition:\")\n            play_composition(\"conservative_composition.mid\")\n            \n            return {\n                \"models\": models,\n                \"compositions\": [composition, creative_composition, conservative_composition]\n            }\n        \n        elif mode == \"custom\":\n            # Generate a new composition with rule-based system using custom parameters\n            print(\"Generating custom rule-based composition...\")\n            generator = HierarchicalMusicGenerator()\n            generator.enhance_sine_wave()\n            \n            # Set custom parameters\n            generator.scale_type = 'minor'\n            generator.bpm = 100\n            generator.root_note = 57  # A3\n            \n            # Generate composition\n            composition = generator.generate_full_composition()\n            \n            # Create MIDI\n            midi_file = generator.create_midi(\"custom_composition.mid\")\n            \n            # Render and play\n            generator.render_audio()\n            generator.save_audio(\"custom_composition.wav\")\n            \n            # Display and play\n            generator.visualize_composition().show()\n            generator.play_audio_fixed()\n            \n            # Also play as MIDI\n            play_composition(midi_file)\n            \n            return generator\n        \n        else:\n            print(f\"Unknown mode: {mode}\")\n            print(\"Available modes: quick_demo, generate_data, train, generate, custom\")\n            return None\n    except Exception as e:\n        print(f\"Error in run_complete_pipeline: {e}\")\n        traceback.print_exc()\n        return None\n\ndef play_all_music_files():\n    \"\"\"Find and play all music files in the current directory\"\"\"\n    try:\n        midi_files = [f for f in os.listdir('.') if f.endswith('.mid')]\n        wav_files = [f for f in os.listdir('.') if f.endswith('.wav')]\n        \n        print(f\"Found {len(midi_files)} MIDI files and {len(wav_files)} WAV files\")\n        \n        # Play MIDI files\n        for midi_file in midi_files:\n            print(f\"\\nPlaying MIDI file: {midi_file}\")\n            play_composition(midi_file)\n        \n        # Play WAV files\n        for wav_file in wav_files:\n            print(f\"\\nPlaying WAV file: {wav_file}\")\n            play_wav_file(wav_file)\n            \n        return True\n    except Exception as e:\n        print(f\"Error playing music files: {e}\")\n        return False\n\ndef main(mode=\"generate_demo\", dataset_size=100, epochs=5, verbose=False):\n    \"\"\"Main function to run the entire hierarchical music generation pipeline.\"\"\"\n    try:\n        tf.get_logger().setLevel('ERROR')  # Reduce TensorFlow verbosity\n        \n        if mode == \"generate_demo\":\n            # Just generate a short demo with the rule-based generator\n            print(\"Generating a short demo with rule-based generator...\")\n            generator = generate_short_demo()\n            return generator\n            \n        elif mode == \"generate_data\":\n            # Generate training dataset using rule-based hierarchical generator\n            print(\"Generating training dataset...\")\n            generator = HierarchicalMusicGenerator()\n            generator.enhance_sine_wave()\n            \n            # Generate a smaller dataset for demonstration purposes\n            dataset = generate_training_dataset(generator, num_samples=dataset_size, verbose=verbose)\n            return dataset\n     \n        elif mode == \"train_models\":\n            # First generate data, then train models\n            print(\"Generating training data and training models...\")\n            generator = HierarchicalMusicGenerator()\n            generator.enhance_sine_wave()\n           \n            # Generate dataset\n            dataset = generate_training_dataset(generator, num_samples=dataset_size, verbose=verbose)\n           \n            # Train models\n            models = train_hierarchical_models(dataset, epochs=epochs)\n            return models\n           \n        elif mode == \"generate_new\":\n            # First train models, then generate new composition\n            print(\"Training models and generating new composition...\")\n            # Generate a small dataset and train models\n            generator = HierarchicalMusicGenerator()\n            generator.enhance_sine_wave()\n           \n            dataset = generate_training_dataset(generator, num_samples=dataset_size, verbose=verbose)\n            models = train_hierarchical_models(dataset, epochs=epochs)\n           \n            # Generate a new composition\n            print(\"Generating new composition from trained models...\")\n            composition = generate_composition(models)\n           \n            # Convert to MIDI\n            midi_file = composition_to_midi(composition, \"standard_composition.mid\")\n           \n            # Generate a few more with different temperatures\n            print(\"\\nGenerating composition with higher temperature (more creative)...\")\n            creative_composition = generate_composition(models, {\n                \"structure\": 1.2,\n                \"phrase\": 1.0,\n                \"note\": 0.8\n            })\n            composition_to_midi(creative_composition, \"creative_composition.mid\")\n           \n            print(\"\\nPlaying the creative composition...\")\n            if os.path.exists(\"creative_composition.mid\"):\n                play_composition(\"creative_composition.mid\")\n           \n            print(\"\\nGenerating composition with lower temperature (more predictable)...\")\n            conservative_composition = generate_composition(models, {\n                \"structure\": 0.6,\n                \"phrase\": 0.5,\n                \"note\": 0.4\n            })\n            composition_to_midi(conservative_composition, \"conservative_composition.mid\")\n            \n            print(\"\\nPlaying the conservative composition...\")\n            if os.path.exists(\"conservative_composition.mid\"):\n                play_composition(\"conservative_composition.mid\")\n           \n            return {\n                \"dataset\": dataset,\n                \"models\": models,\n                \"compositions\": [composition, creative_composition, conservative_composition]\n            }\n       \n        else:\n            print(f\"Unknown mode: {mode}\")\n            print(\"Available modes: generate_demo, generate_data, train_models, generate_new\")\n            return None\n            \n    except Exception as e:\n        print(f\"Error in main function (mode={mode}): {e}\")\n        traceback.print_exc()\n        print(\"\\nFalling back to simple demo generation...\")\n        return generate_short_demo()\n\n\n# Uncomment one of these to run the appropriate operation\n# generator = main(mode=\"generate_demo\")  # Just generate a short music demo\n# dataset = main(mode=\"generate_data\", dataset_size=10, verbose=False)  # Generate training data\n# models = main(mode=\"train_models\", dataset_size=10, epochs=2)  # Train models\n# results = main(mode=\"generate_new\", dataset_size=50, epochs=2)  # This creates various compositions\n\n# Alternatively, use the run_complete_pipeline function for a more guided experience\n# run_complete_pipeline(\"quick_demo\")  # Generate and play a short demo\nrun_complete_pipeline(\"custom\")      # Generate with custom parameters\n# play_all_music_files()              # Play all existing MIDI and WAV files","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-17T20:34:56.664031Z","iopub.execute_input":"2025-04-17T20:34:56.664396Z","iopub.status.idle":"2025-04-17T20:35:44.358666Z","shell.execute_reply.started":"2025-04-17T20:34:56.664368Z","shell.execute_reply":"2025-04-17T20:35:44.357295Z"}},"outputs":[],"execution_count":null}]}